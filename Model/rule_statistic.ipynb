{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rule_dataset.csv')\n",
    "\n",
    "def clean_braces(x):\n",
    "    x = x.replace(\"()\", \"\").replace(\",\", \"\").replace(\" \", \"\")\n",
    "    return str(x)\n",
    "def add_braces(x):\n",
    "    x = x+\"()\"\n",
    "    return x\n",
    "\n",
    "df['Syscall'] = df['Syscall'].apply(clean_braces)\n",
    "df.head(3)\n",
    "\n",
    "# df['Syscall'] = df['Syscall'].apply(add_braces)\n",
    "# df.to_csv(\"rule_dataset.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 印出各類別的個數和內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityType_lst = df['EntityType'].unique()\n",
    "lenSyscall = len(df['Syscall'].unique())\n",
    "lenEnVerb = len(df['EnVerb'].unique())\n",
    "print(f\"For total {lenSyscall:2} uq syscalls & {lenEnVerb:2} uq verbs\\n\")\n",
    "\n",
    "for entityType in entityType_lst:\n",
    "    dataFileType = df[df['EntityType'] == entityType]\n",
    "    lenEnTp = len(dataFileType)\n",
    "    lenSyscall = len(dataFileType['Syscall'].unique())\n",
    "    lenEnVerb = len(dataFileType['EnVerb'].unique())\n",
    "    actionType_lst = dataFileType['ActionType'].unique()\n",
    "\n",
    "    print(f\"EntityType: {entityType:<6} has {lenSyscall:2} uq syscalls & {lenEnVerb:2} uq verbs & {len(actionType_lst):2} actionType\")\n",
    "\n",
    "    for actionType in actionType_lst:\n",
    "        dataActionType = dataFileType[dataFileType['ActionType'] == actionType]\n",
    "        lenSyscall = len(dataActionType['Syscall'].unique())\n",
    "        lenEnVerb = len(dataActionType['EnVerb'].unique())\n",
    "\n",
    "        print(f\"\\t{actionType:<12} has {lenSyscall:2} uq syscalls & {lenEnVerb:2} uq verbs\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試寫 rule\n",
    "- input: object 和 entityType\n",
    "- output: 對應的 syscall (1或多個)\n",
    "- Todo:\n",
    "    1. 寫規則\n",
    "    2. 回OPser導出資料\n",
    "    3. 測試規則\n",
    "    4. 擴充資料集 (source=report & expend 同義詞)\n",
    "    5. extract BERT word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EntityType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationEvaluator:\n",
    "    def __init__(self) -> None:\n",
    "        self.df = self.read_rule()\n",
    "        self.update_syscall_list = list(self.df[self.df['ActionType'].isin(['UPDATE'])]['Syscall'].unique())\n",
    "        pass\n",
    "\n",
    "    def read_rule(self) -> pd.DataFrame:\n",
    "        df = pd.read_csv('rule_dataset.csv')\n",
    "\n",
    "        def clean_braces(x):\n",
    "            x = x.replace(\"()\", \"\").replace(\",\", \"\").replace(\" \", \"\")\n",
    "            return str(x)\n",
    "\n",
    "        df['Syscall'] = df['Syscall'].apply(clean_braces)\n",
    "        return df\n",
    "\n",
    "    def translate_rule(self, entityType: str, enVerb: str, object: str=None) -> list[str] | None:\n",
    "        ''' translate a given enverb into system call(s) with hardcoded rule '''\n",
    "        entityType = entityType.upper()\n",
    "        if entityType.startswith('PROC'):\n",
    "            entityType = 'PROC'\n",
    "        if entityType.startswith('NET'):\n",
    "            entityType = 'NET'\n",
    "        if entityType.startswith('INFO'):\n",
    "            entityType = 'INFO'\n",
    "        entityType_lst = ['FILE', 'PROC', 'DEVICE', 'INFO', 'NET']\n",
    "        if entityType not in entityType_lst:\n",
    "            return None\n",
    "        \n",
    "        # Get rules belongs to this entityType\n",
    "        dataFileType = self.df[self.df['EntityType'] == entityType]\n",
    "        dataEnVerb = dataFileType.loc[dataFileType['EnVerb'].isin([enVerb])]\n",
    "        if len(dataEnVerb) == 0:\n",
    "            return None\n",
    "        return list(dataEnVerb['Syscall'].unique())\n",
    "\n",
    "    def resolve(self, entityType: str, syscall:str, en_verb:str, downcast=False) -> bool:\n",
    "        hit, isSysChange = False, False\n",
    "        corresponding_syscall_list = self.translate_rule(entityType, en_verb)\n",
    "        if corresponding_syscall_list and syscall in corresponding_syscall_list:\n",
    "            hit = True\n",
    "        elif entityType.upper() == \"FILE\" and syscall in self.update_syscall_list:\n",
    "            isSysChange = True\n",
    "        return hit, isSysChange\n",
    "\n",
    "# test\n",
    "oE = OperationEvaluator()\n",
    "oE.translate_rule('FILE', 'read') # ['read', 'readlink']\n",
    "ans_syscalls = oE.translate_rule('FILE', 'change') # ['rename', 'fchmod', 'chmod', 'lchmod']\n",
    "print(ans_syscalls)\n",
    "ans_syscalls = oE.translate_rule('PROC', 'change') # ['ptrace', 'brk']\n",
    "print(ans_syscalls)\n",
    "ans_syscalls = oE.translate_rule('FILE', 'create') # ['dup', 'dup2', 'open', 'mmap', 'link']\n",
    "print(ans_syscalls)\n",
    "ans_syscalls = oE.translate_rule('PROC', 'create') # ['clone', 'fork', 'vfork']\n",
    "print(ans_syscalls)\n",
    "ans_syscalls = oE.translate_rule('NET', 'create') # ['pipe', 'socket']\n",
    "print(ans_syscalls)\n",
    "\n",
    "# test\n",
    "res = oE.resolve('FILE','linkat', 'read') # (False, False)\n",
    "print(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained BERT model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
