{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luweb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning:IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, List, get_type_hints\n",
    "from styleframe import StyleFrame, Styler\n",
    "from IPython.display import display\n",
    "\n",
    "''' 自己寫的模組 '''\n",
    "from cc_regex_script import RegexMatchResult, RegexMaster \n",
    "from cc_nlp_script import find_verb_of_vocab, OperationMode, OperationEvaluator\n",
    "from ASG import AttackGraph, Node, Edge, FileTable #, build\n",
    "import Utility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 所有 ASG 的 trace logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samplename: ['95776f31cbcac08eb3f3e9235d07513a6d7a6bf9f1b7f3d400b2cf0afdb088a7']\n"
     ]
    }
   ],
   "source": [
    "family = 'Conti' # Dofloo Xorddos Darlloz\n",
    "\n",
    "sample_dict = {\n",
    "    'Dofloo': ['60f879ed44de37351c973f01d0d77f79'],  # 只先使用這個 dof sample  0046a78514a658b9b7a4e29e8581f85b\n",
    "    'Xorddos': ['0aefb67c01a24d05351b093455203fa2'], # 只先使用這個 xor sample\n",
    "    'Darlloz': ['dfeb77cb0ba28ac3ba4be55d7bc91fad'], # 只先使用這個 dar sample\n",
    "    'Gafgyt': ['933e9eff97f50b196b2bb0fef499640e'],  # 只先使用這個 gaf sample\n",
    "    'Luabot': ['a220940db4be6878e47b74403a8079a1'],  # 只先使用這個 lua sample\n",
    "    'Lupper': ['a220940db4be6878e47b74403a8079a1'],  # 只先使用這個 lua sample\n",
    "    'Kaiten': ['19bc282193a9a792aeab3eb826c73976'],  # 只先使用這個 kai sample\n",
    "    'Turla': ['19fbd8cbfb12482e8020a887d6427315'],   # 只先使用這個 tur sample\n",
    "    'BPFDoor': ['5faab159397964e630c4156f8852bcc6ee46df1cdd8be2a8d3f3d8e5980f3bb3'],\n",
    "    'Conti': ['95776f31cbcac08eb3f3e9235d07513a6d7a6bf9f1b7f3d400b2cf0afdb088a7'],\n",
    "    'ChinaZ': ['14afd7d319cf271a7d871f297a27eac388d7f0381a1fc0691b18a8dd15ddf327'],\n",
    "    'Defray777': ['da3bb9669fb983ad8d2ffc01aab9d56198bd9cedf2cc4387f19f4604a070a9b5'],\n",
    "    'Demonbot': ['9de853e88ba363b124dfce61bc766f8f42c84340c7bd2f4195808434f4ed81e3'],\n",
    "    'EvilGnome': ['7ffab36b2fa68d0708c82f01a70c8d10614ca742d838b69007f5104337a4b869'],\n",
    "    'FontOnLake': ['602c435834d796943b1e547316c18a9a64c68f032985e7a5a763339d82598915'],\n",
    "    'HCRootkit': ['6187541be6d2a9d23edaa3b02c50aea644c1ac1a80ff3e4ddd441b0339e0dd1b'],\n",
    "    'KEYPLUG': ['99b36963f0e93a5c59cbd205d102f6b850f02f5e74ac4f66257b6f38d9c9ef5a'],\n",
    "    'Lightning': ['fd285c2fb4d42dde23590118dba016bf5b846625da3abdbe48773530a07bcd1e'],\n",
    "    'Melofee': ['407ab8618fed74fdb5fd374f3ed4a2fd9e8ea85631be2787e2ad17200f0462b8'],\n",
    "    'XMRigMiner': ['01a1aa3cd4831197c4c97164d721dca41bbec2ba98ec6813979dcb2820ab44e1'],\n",
    "    '': [''],\n",
    "}\n",
    "samplename_lst = sample_dict[family]\n",
    "print('samplename:', samplename_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{<OP act=a, obj=a>}\n"
     ]
    }
   ],
   "source": [
    "def prettifyName(item:str) -> str:\n",
    "    pretty_name = {\n",
    "        r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\": \"ip_addr/ip_addr:port/port\",\n",
    "        r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+\": \"ip_addr/ip_addr:port/port\", \n",
    "        r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:d+\":  \"ip_addr/ip_addr:port/port\",\n",
    "        r\"0x[0-9a-zA-Z]{8}\": \"0x[0-9a-zA-Z]{8} (mem)\",       # old\n",
    "        r\"0x[0-9a-zA-Z]{1,16}\": \"0x[0-9a-zA-Z]{1,16} (mem)\", # new\n",
    "        r\"Permission\":                 'Permission/Permission:[0-9]{3}',\n",
    "        r\"Permission:[0-9]{3}\":        'Permission/Permission:[0-9]{3}',\n",
    "        # r\"permission:{0,1}[0-9]{0,4}\": 'Permission/Permission:[0-9]{3}'\n",
    "    }\n",
    "    changed = pretty_name.get(item, None)\n",
    "    if changed:\n",
    "        return changed\n",
    "    return item\n",
    "\n",
    "class PrettyJson(dict):\n",
    "\tdef __str__(self):\n",
    "\t\treturn json.dumps(self, indent=4, sort_keys=True)\n",
    "# myJSON = PrettyJson(student) # usage\n",
    "\n",
    "class OperationPair:\n",
    "    SYSCALL = 0\n",
    "    VERB = 1    # not use now (may cause confused)\n",
    "\n",
    "    def __init__(self, action:str, object:str, isSyscall:bool=False, subject:str=None, \\\n",
    "                 step_number:int=None , original_object=None, \\\n",
    "                 original_sentence=None, object_type=None):\n",
    "        self.object:str = object # regex\n",
    "        self.action:str = action # verb or syscall\n",
    "        self.isSyscall:bool = isSyscall # action type (syscall or verb)\n",
    "        self.object_type:str = object_type # FILE, NET, PROC, MEM, INFO\n",
    "        self.subject:str = subject\n",
    "        self.step_number:int = step_number\n",
    "        self.original_object:str = original_object # can store original matched word (object) from CTD\n",
    "        self.original_sentence:str = original_sentence # can store the mathced sentence\n",
    "        self.altVerb:str = None # can store the alternative verb if the origin verb is not in the rule\n",
    "        pass\n",
    "\n",
    "    def __eq__(self, other): \n",
    "        if not isinstance(other, OperationPair):\n",
    "            # don't attempt to compare against unrelated types\n",
    "            return NotImplemented\n",
    "        # Same if <action, object> pair is same (type is not consider yet)\n",
    "        return self.action == other.action and self.object == other.object\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        # necessary for instances to behave sanely in dicts and sets.\n",
    "        return hash((self.action, self.object))\n",
    "\n",
    "    def _getActionStr(self) -> str:\n",
    "        if self.isSyscall:\n",
    "            return f\"{self.action}()\"\n",
    "        return self.action\n",
    "    def __str__(self) -> str:\n",
    "        if self.step_number:\n",
    "            return f\"<OP{self.step_number:>2} act={self._getActionStr()}, obj={prettifyName(self.object)}>\"\n",
    "        return f\"<OP act={self._getActionStr()}, obj={prettifyName(self.object)}>\"\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "    def getSentStr(self) -> str:\n",
    "        '''return string contains original_object & flat_sentence'''\n",
    "        flat_sentence = \" \".join(self.original_sentence.splitlines())\n",
    "        return f\"<OP{self.step_number:>2} act={self._getActionStr()}, obj={prettifyName(self.original_object)}, sent={flat_sentence}>\"\n",
    "        \n",
    "# test case\n",
    "p_aa = OperationPair('a','a')\n",
    "p_aaz = OperationPair('a','a')\n",
    "p_ab = OperationPair('a','b')\n",
    "\n",
    "print(p_aa == p_aaz) # True\n",
    "print(set([p_aa, p_aaz])) # one element\n",
    "\n",
    "def construct_sample_OPset(step_list: list, regexMaster:RegexMaster, keep_src_node=False, debug=False, \n",
    "                           rt_order=True, draw_memory_etc=False) -> set | tuple[set, list]:\n",
    "    '''return a list of OPset. RegexMaster and family are gobal variable.\n",
    "     If draw_memory_etc = True, 則會特別處理記憶體, 網路, 權限等節點的 dst_node.'''\n",
    "    if debug:\n",
    "        print('step_list len:', len(set(step_list)))\n",
    "    OPlst_raw = list((src_node.name, dst_node.name, syscall) for (src_node, dst_node, syscall) in step_list) # object is raw\n",
    "    OPset_raw = list(dict.fromkeys(OPlst_raw))\n",
    "    if debug:\n",
    "        print('OPlst_raw len:', len(OPlst_raw)) # why len is 123100? (while step_list len is 7775) (must be equal)\n",
    "        print(f\"OPlst_raw: {OPlst_raw[:10]}\")\n",
    "        print('OPset_raw len:', len(OPset_raw)) # len is 5925 for xor\n",
    "        print(f\"OPset_raw: {OPset_raw[:10]}\")\n",
    "    # regexMaster = RegexMaster()\n",
    "    # regex_pool = regexMaster.get_all_regex()\n",
    "    OPset = set()\n",
    "    OPset_ordered = list()\n",
    "    for (src_node, dst_node, syscall) in OPset_raw:\n",
    "        # regex_dst_node_list = RegexMaster.find_spacial_token_with_regex(regex_pool, dst_node)\n",
    "        regex_dst_node_list:list[RegexMatchResult] = regexMaster.find_spacial_token(dst_node)\n",
    "\n",
    "        # 0509 加的，為了畫圖\n",
    "        if draw_memory_etc and dst_node in ['Memory Address', 'NIC', ]:\n",
    "            if dst_node == 'Memory Address':\n",
    "                txt = 'Memory Address'\n",
    "                regex_dst_node_list = [RegexMatchResult(txt, match_regex='0x[0-9a-zA-Z]{1,16}', type='MEM')]\n",
    "            else:\n",
    "                txt = 'NIC'\n",
    "                regex_dst_node_list = [RegexMatchResult(txt, match_regex='^eth.*', type='NET')]\n",
    "        if draw_memory_etc and dst_node in ['\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}', 'port \\\\d+', \n",
    "                                            '\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}:\\\\d+']:\n",
    "            txt = 'ip_addr/ip_addr:port/port'\n",
    "            regex_dst_node_list = [RegexMatchResult(txt, match_regex=txt, type='NET')]\n",
    "        if draw_memory_etc and dst_node in ['Permission', 'Permission:[0-9]{3}']:\n",
    "            txt = 'Permission/Permission:[0-9]{3}'\n",
    "            regex_dst_node_list = [RegexMatchResult(txt, match_regex=txt, type='FILE')]\n",
    "\n",
    "        if regex_dst_node_list is None or len(regex_dst_node_list) == 0:\n",
    "            continue\n",
    "        for regex_result in regex_dst_node_list:\n",
    "            dst_node = regex_result.match_regex\n",
    "            step_number = len(OPset) + 1\n",
    "            if keep_src_node:\n",
    "                op = OperationPair(syscall, dst_node, subject=src_node, isSyscall=True,\\\n",
    "                                   step_number=step_number, object_type=regex_result.type)\n",
    "                OPset.add(op) # keep src_node in OP\n",
    "                if op not in OPset_ordered:\n",
    "                    OPset_ordered.append(op)\n",
    "            else:\n",
    "                op = OperationPair(syscall, dst_node, isSyscall=True,\\\n",
    "                                   step_number=step_number, object_type=regex_result.type)\n",
    "                OPset.add(op) # only dst_node, syscall in OP\n",
    "                if op not in OPset_ordered:\n",
    "                    OPset_ordered.append(op)\n",
    "    if debug:\n",
    "        print('OPset len:', len(OPset), 'OPset_ordered len:', len(OPset_ordered))\n",
    "    if rt_order:\n",
    "        return OPset, OPset_ordered\n",
    "    return OPset\n",
    "\n",
    "# test\n",
    "# sample_OPset = construct_sample_OPset(asg.step_list, debug=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ASG object and Sample object，計算並儲存其 regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path is correct: True\n",
      "Exam: sample S1 matches 2 of regex, # of unique raw objects: 5, # of unique steps: 11\n",
      "Size of total_used_regex: 2\n"
     ]
    }
   ],
   "source": [
    "class Sample:\n",
    "    def __init__(self, samplename:str, regex_set:set=None, special_token_dict=None, \\\n",
    "                 step_list=None, regexMaster=None) -> None:\n",
    "        self.samplename: str = samplename\n",
    "        self.regexMaster = None\n",
    "        if regexMaster:\n",
    "            self.regexMaster = regexMaster\n",
    "        self.regex_set: set = set()\n",
    "        if regex_set:\n",
    "            self.regex_set = regex_set\n",
    "        self.special_token_dict = {}\n",
    "        if special_token_dict:\n",
    "            self.special_token_dict: dict = special_token_dict # list of dict\n",
    "        if step_list:\n",
    "            self.step_list = step_list\n",
    "            OPset, OPset_ordered = construct_sample_OPset(step_list, self.regexMaster, draw_memory_etc=True)\n",
    "            self.OPset: set[OperationPair] = OPset\n",
    "            self.OPset_ordered: list[OperationPair] = OPset_ordered # 依照出現順序排序的 OPset (元素相同順序不同)\n",
    "            self.OPset_sysOnly_ordered = [] # 尚未初始化 只儲存改變系統狀態的 OP 的物件\n",
    "            self.OPset_sysOnly_ordered_index = [] # 尚未初始化 只儲存改變系統狀態的 OP 的 index\n",
    "            self.ASGstep_sysOnly_ordered_index = [] # 尚未初始化 只儲存改變系統狀態的 ASG 的 index\n",
    "            del OPset, OPset_ordered\n",
    "        pass\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<Sample self.samplename>\"\n",
    "\n",
    "''' 讀取 ASG 中的 set_of_object (就是這個樣本的 special_token_dict)，並歸納樣本的 regex_set '''\n",
    "# regexMaster = RegexMaster()\n",
    "# regex_pool = regexMaster.get_all_regex()\n",
    "# total_used_regex = set()\n",
    "samples: list[Sample] = []\n",
    "total_used_regex = set()\n",
    "for samplename in samplename_lst:\n",
    "\n",
    "    # trace_path = f\"../../C ASG/trace/{family}/{samplename}.bin\"\n",
    "    # asg = AttackGraph(trace_path)\n",
    "    # asg.create()\n",
    "    asgpkl_path = f\"../../C ASG statistics 1115ver/saved_pkl/{family}/{samplename}.pkl\"\n",
    "    print(\"path is correct:\", os.path.exists(asgpkl_path))\n",
    "    with open(asgpkl_path, 'rb') as fp:\n",
    "        asg:AttackGraph = pickle.load(fp)\n",
    "\n",
    "    regexMaster = RegexMaster(asg)\n",
    "\n",
    "    sample = Sample(samplename, special_token_dict=asg.set_of_object, step_list=asg.step_list, \\\n",
    "                    regexMaster=regexMaster)\n",
    "    sample.regex_set = regexMaster.get_used_regex() # used_regex_set has bug 有些抓不到\n",
    "    samples.append(sample)\n",
    "    total_used_regex = total_used_regex | sample.regex_set\n",
    "\n",
    "    # with open(f'../../C ASG statistics 1115ver/saved_pkl/{family}/{samplename}.pkl', 'rb') as inp:\n",
    "    #     # asg: AttackGraph = pickle.load(inp) # asg.set_of_object is dict() (key:spacial token, value: type 首字大寫)\n",
    "    #     sample = Sample(samplename, special_token_dict=asg.set_of_object, step_list=asg.step_list)\n",
    "    #     regexMaster = RegexMaster(asg)\n",
    "    #     regex_pool = regexMaster.get_all_regex()\n",
    "    #     sample.regex_set = set(regex_pool) # 直接使用志剛寫的作為這個樣本的 baseline\n",
    "    #     # for obj in sample.special_token_dict.keys():\n",
    "    #     #     matched_list: list[RegexMatchResult] = regexMaster.find_spacial_token(obj)\n",
    "    #     #     if matched_list:\n",
    "    #     #         # print(obj, matched_list)\n",
    "    #     #         [sample.regex_set.add(m.match_regex) for m in matched_list]\n",
    "    #     #         # [total_used_regex.add(m.match_regex) for m in matched_list]\n",
    "    #     # print('------', sample.regex_set)\n",
    "    #     # break\n",
    "    #     samples.append(sample)\n",
    "    # del asg\n",
    "seen_node_S, seen_node_O = Utility.create_set_of_objects(asg)\n",
    "raw_objects = set(seen_node_S)  # 理論上 seen_node_S 比 seen_node_O 多一個 malware node 而已\n",
    "raw_objects.update(seen_node_O)\n",
    "print(f'Exam: sample S1 matches {len(samples[0].regex_set)} of regex, # of unique raw objects: {len(seen_node_O)}\\\n",
    ", # of unique steps: {len(Utility.get_uni_step(asg))}')\n",
    "print(f'Size of total_used_regex: {len(total_used_regex)}')\n",
    "regex_match_file, regex_non_match_file = Utility.build_file_regex(Utility.get_set_of_objects_file(asg), Utility.build_RULES_DICT()) # file re -> obj relation\n",
    "\n",
    "# Create Visualization Instance\n",
    "img_path = '../../Graph & Diagram/'\n",
    "# g = asg.draw(True)\n",
    "# g.render(f\"{img_path}{family}\", format='svg') #  view=True # save svg img file, and a dot file\n",
    "# del g\n",
    "\n",
    "# print(len(samples[0].OPset)) # 52  ''' Notes: always use samples[0].regex_set, dont get regex from sample.OPset '''\n",
    "# samples[0].OPset\n",
    "# obj_in_opset = set([op.object for op in samples[0].OPset])\n",
    "# print(len(obj_in_opset), obj_in_opset) # 23\n",
    "# len(samples[0].regex_set) # 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 info []\n",
      "1 file ['.*/dracut/.*']\n",
      "0 net []\n",
      "0 ID []\n",
      "0 proc []\n",
      "1 mem ['0x[0-9a-zA-Z]{1,16}']\n"
     ]
    }
   ],
   "source": [
    "print(len(regexMaster.info_regex),'info',regexMaster.info_regex)\n",
    "print(len(regexMaster.file_regex),'file',regexMaster.file_regex)\n",
    "print(len(regexMaster.net_regex),'net',regexMaster.net_regex)\n",
    "print(len(regexMaster.ID_regex),'ID',regexMaster.ID_regex)\n",
    "print(len(regexMaster.proc_regex),'proc',regexMaster.proc_regex)\n",
    "print(len(regexMaster.mem_regex),'mem',regexMaster.mem_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Save result to txt file 沒事不要 run ! '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Save result to txt file 沒事不要 run ! '''\n",
    "# total_regex = set()\n",
    "# with open('./result/countof_regexset.txt', 'w', encoding='utf-8') as opf:\n",
    "#     # header\n",
    "#     opf.write('{:12s}'.format('Sample no.'))\n",
    "#     for i in range(len(samples)):\n",
    "#         if i+1 < 10:\n",
    "#             opf.write(f' S{i+1} ')\n",
    "#         else:\n",
    "#             opf.write(f'S{i+1} ')\n",
    "#     opf.write('\\n')\n",
    "#     # opf.write('{:12s}'.format('# of regex'))\n",
    "#     num_of_regex_string = '{:12s}'.format('# of regex')\n",
    "#     num_of_objects_string = '{:12s}'.format('# of object ') # 所有的類別喔! 無過濾\n",
    "#     for i in range(len(samples)):\n",
    "#         # opf.write(f'{len(samples[i].regex_set):>3} ')\n",
    "#         num_of_regex_string += f'{len(samples[i].regex_set):>3} '\n",
    "#         num_of_objects_string += f'{len(samples[i].special_token_dict):>3} '\n",
    "#     opf.write(num_of_objects_string+'\\n')\n",
    "#     opf.write(num_of_regex_string)\n",
    "#     opf.write('\\n{:12s}'.format('Sample hash'))\n",
    "#     for i in range(len(samples)):\n",
    "#         opf.write(f'{samples[i].samplename[:3]:>3} ')\n",
    "#     opf.write('\\n\\n')\n",
    "#     opf.write(f'Size of regex_pool: {len(regex_pool)}, size of total_used_regex: {len(regexMaster.used_regex_set)}\\n\\n')\n",
    "\n",
    "#     # content of each sample\n",
    "#     for i,s in enumerate(samples):\n",
    "#         content_1 = f\"S{i+1} has {len(s.regex_set)} of regex\\n\"\n",
    "#         content_2 = f\"regex_set: {s.regex_set}\\n\"\n",
    "#         content_3 = f\"special_token_dict: {s.special_token_dict.keys()}\\n\"\n",
    "#         opf.writelines([content_1, content_2, content_3])\n",
    "#         opf.write('\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conti.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_fir_path = '../../C parse report/sentence csvs/'\n",
    "# family, samplename, outputfolder = 'Xorddos', '???', './result'\n",
    "outputfolder = './result'\n",
    "\n",
    "def get_all_filenames(dir: str='./') -> list:\n",
    "    ''' traverse root directory, and list directories as dirs and files as files. Return filenames in rootdir. '''\n",
    "    files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "xor_report_names = [f for f in get_all_filenames(report_fir_path) if f.startswith(family)] # 只選擇這個家族的報告\n",
    "xor_report_dfs = [pd.read_csv(f\"{report_fir_path}{f}\") for f in xor_report_names]\n",
    "for df in xor_report_dfs:\n",
    "    df['Content'] = df['Content'].apply(lambda x: str(x).strip('.')) # 移除句點\n",
    "xor_report_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence 1</td>\n",
       "      <td>CRIMEWARE\\nHypervisor Ransomware | Multiple Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence 2</td>\n",
       "      <td>\\nExecutive Summary\\nSentinelLabs identified 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence 3</td>\n",
       "      <td>These variants emerged through H2 2022 and H1 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number                                            Content\n",
       "0  Sentence 1  CRIMEWARE\\nHypervisor Ransomware | Multiple Th...\n",
       "1  Sentence 2  \\nExecutive Summary\\nSentinelLabs identified 1...\n",
       "2  Sentence 3  These variants emerged through H2 2022 and H1 ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_report_dfs[0][:3]\n",
    "# xor_report_dfs[0].loc[5]['Content']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 單篇文章的 Class 和 整個 Family 的 Class\n",
    "`baseline: Dict[str, list]` 改為 `regexMaster: RegexMaster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self) -> None:\n",
    "        self.numOfSTobj:int = 0\n",
    "        self.numOfSTsys:int = 0\n",
    "        self.objN:int = 0    # 物件分子\n",
    "        self.objD:int = 0    # 物件分母\n",
    "        self.objSysN:int = 0 # 系統設定檔物件分子\n",
    "        self.objSysD:int = 0 # 系統設定檔物件分母\n",
    "        self.opN:int = 0     # 動作和物件分子\n",
    "        self.opD:int = 0     # 動作和物件分母\n",
    "        self.opSysN:int = 0  # 動作和系統物件分子\n",
    "        self.opSysD:int = 0  # 動作和系統物件分母\n",
    "        pass\n",
    "    def safe_divide(self, num, denom):\n",
    "        if denom == 0:\n",
    "            return 0\n",
    "            # raise ZeroDivisionError(\"Error: Denominator cannot be zero.\")\n",
    "        return num / denom\n",
    "    \n",
    "    def setObj(self, num, denom) -> float:\n",
    "        self.objN, self.objD = num, denom\n",
    "        return self.safe_divide(self.objN, self.objD)\n",
    "    def setObjSys(self, num, denom) -> float:\n",
    "        self.objSysN, self.objSysD = num, denom\n",
    "        return self.safe_divide(self.objSysN, self.objSysD)\n",
    "    def setOp(self, num, denom) -> float:\n",
    "        self.opN, self.opD = num, denom\n",
    "        return self.safe_divide(self.opN, self.opD)\n",
    "    def setOpSys(self, num, denom) -> float:\n",
    "        self.opSysN, self.opSysD = num, denom\n",
    "        return self.safe_divide(self.opSysN, self.opSysD)\n",
    "    \n",
    "    def getMetricObj(self) -> float:\n",
    "        return self.safe_divide(self.objN, self.objD)\n",
    "    def getMetricObjSys(self) -> float:\n",
    "        return self.safe_divide(self.objSysN, self.objSysD)\n",
    "    def getMetricOp(self) -> float:\n",
    "        return self.safe_divide(self.opN, self.opD)\n",
    "    def getMetricOpSys(self) -> float:\n",
    "        return self.safe_divide(self.opSysN, self.opSysD)\n",
    "    \n",
    "class SpecialToken:\n",
    "    def __init__(self, STobject:str, STregex:str, type=None) -> None:\n",
    "        self.object:str = STobject\n",
    "        self.regex:str = STregex\n",
    "        self.isSysResource:bool = False\n",
    "        if '/etc' in STregex:\n",
    "            self.isSysResource = True\n",
    "        self.type:str = ''\n",
    "        if type:\n",
    "            self.type = type\n",
    "        pass\n",
    "    \n",
    "class ReportEvalModel:\n",
    "    def __init__(self, regexMaster:RegexMaster, sentences: pd.DataFrame, reportname:str='', regex_set: set=None):\n",
    "        # self.regex_set: set[str] = regex_set # 樣本or家族含有的 regex 集合\n",
    "        self.sentences = sentences # a df\n",
    "        self.reportname = reportname\n",
    "        cols = list(total_used_regex) # be careful! is global variable!!\n",
    "        self.match_tbl = pd.DataFrame([[0]*len(cols)]*len(sentences), columns=cols)\n",
    "        self.match_word:dict[(int,str), str] = dict() # key(idx_sent,regex) value(word:str)\n",
    "        self.match_regex = set()\n",
    "        self.doc_OPset:set[OperationPair] = set() # Set of doc's OperationalPair\n",
    "        self.match_doc_OPset:set[OperationPair] = set()\n",
    "        self.OPset_order_index = [] # 紀錄 ASG OP 的出現順序 (lifecycle)\n",
    "        self.SysOPset_order_index = [] # 只紀錄改變系統的 OP\n",
    "        self.ASGstep_order_index = []  # 紀錄 ASG step 的出現順序 (lifecycle/attackflow)\n",
    "        self.SysASGstep_order_index = []\n",
    "        # self.asgSysOPset_order_index = []\n",
    "        self.regexMaster = regexMaster # 其實應該用 class function 就不用傳入一個物件，樣本or家族含有的 regex 集合\n",
    "        self.matched_syscalls:dict[tuple,list] = {} # key:(verb, regex), value: list of syscalls\n",
    "        self.matched_sent_id:list[int] = []\n",
    "        self.STlist:list[SpecialToken] = []  # 這篇文章包含哪些 special token word (可重複)\n",
    "        self.STcounter:Counter = None\n",
    "        self.metric:Metric = None # 紀錄指標的分數\n",
    "        self.match()\n",
    "\n",
    "    def match(self) -> None:\n",
    "        '''find baseline in sentences of report. Fill matching result in self.match_tbl.'''\n",
    "        sentence_list = self.sentences['Content']\n",
    "        patterns = regexMaster.get_used_regex()\n",
    "        # print(f'\\ndocument name: {self.reportname}')\n",
    "        for idx_sent, sent in enumerate(sentence_list):\n",
    "            # print(idx_sent, sent)\n",
    "            # find regexs in a sentence (STobjects)\n",
    "            matched_list: list[RegexMatchResult] = regexMaster.find_spacial_token(sent)\n",
    "            for pattern in list(patterns):\n",
    "                matches = re.findall(pattern, sent) # Exp6 負責\n",
    "                for match in matches:\n",
    "                    # print(f'match: {match:10}, pattern: {pattern}')\n",
    "                    self.STlist.append(SpecialToken(match, pattern, \\\n",
    "                                                        regexMaster.get_regex_type(pattern)))\n",
    "            if not matched_list:\n",
    "                continue\n",
    "            self.matched_sent_id.append(idx_sent)\n",
    "            for m in matched_list:\n",
    "                this_re = m.match_regex\n",
    "                # matched_word = m.word\n",
    "                # print(matched_word, '|',sent[:10])\n",
    "                self.match_word[(idx_sent,this_re)] = m.word # 紀錄被 search 到的單字\n",
    "                # self.match_tbl.loc[idx_sent,this_re] = 1 # mark as found 節省空間\n",
    "                self.match_regex.add(this_re)\n",
    "                en_verb = find_verb_of_vocab(sent, m.word)\n",
    "                # if m.word == \"sed\": # 檢查某個物件的動詞判斷情形\n",
    "                #     print(\"sed + verb:\", en_verb, \"in sentence:\", sent[:20])\n",
    "                # print(f\"---\\nen_verb: {en_verb}, m.word: {m.word}, sent: {sent}\") # 列印所有動詞抓取情形\n",
    "                stepn = len(self.doc_OPset) + 1\n",
    "                # 如果 action 和 matched regex 相同，即使報告中object的原字串不同，也不會多計入。\n",
    "                if en_verb:\n",
    "                    self.doc_OPset.add(OperationPair(en_verb, this_re, original_object=m.word, \n",
    "                    step_number=stepn, original_sentence=sent, object_type=m.type)) # has verb\n",
    "                else:\n",
    "                    self.doc_OPset.add(OperationPair(None, this_re, original_object=m.word, \n",
    "                                                     step_number=stepn, object_type=m.type, \n",
    "                                                     original_sentence=sent)) # no verb\n",
    "\n",
    "        self.STcounter = Counter([st.regex for st in self.STlist])\n",
    "        pass\n",
    "    \n",
    "    def get_match_sentences(self) -> pd.DataFrame:\n",
    "        result = self.match_tbl.copy()\n",
    "        result['match'] = result.sum(axis=1)\n",
    "        return result\n",
    "    \n",
    "    def get_match_regexs(self) -> set:\n",
    "        return self.match_regex\n",
    "\n",
    "    def get_match_word(self, idx_sent:int, regex:str) -> str:\n",
    "        return self.match_word[(idx_sent, regex)]\n",
    "\n",
    "class FamilySet:\n",
    "    '''一個 malware family report 集合'''\n",
    "    def __init__(self, familyname:str, regexMaster: RegexMaster, sample: Sample=None):\n",
    "        self.familyname = familyname\n",
    "        self.regexMaster = regexMaster\n",
    "        self.num_of_used_regex = len(regexMaster.used_regex_set) # 這個家族含規則的總數量 (unoin by all samples)\n",
    "        self.sample = None\n",
    "        if sample:\n",
    "            self.sample = sample\n",
    "            self.num_of_used_regex = len(sample.regex_set) # 改以這個樣本規則的總數量為基準\n",
    "        self.rem_lst: List[ReportEvalModel] = [] # list of ReportEvalModel under this family\n",
    "        self.result_tbl = None\n",
    "\n",
    "    def add_rem(self, sentences: pd.DataFrame, reportname: str=''):\n",
    "        '''新增 report 到 FamilySet 中，需傳入文本和報告名稱，會沿用 FamilySet 的 baseline.'''\n",
    "        if self.sample:\n",
    "            rem = ReportEvalModel(self.regexMaster, sentences, reportname) # 基準是 Sample\n",
    "            self.rem_lst.append(rem)\n",
    "            return\n",
    "        # (legacy) no such condition\n",
    "        # rem = ReportEvalModel(self.regexMaster, sentences, reportname) # 基準是 Family union # need fix -> no first arg now\n",
    "        self.rem_lst.append(rem)\n",
    "\n",
    "    def calc_report_coverage_score(self, match_regexs: list[str], apply_weight=False) -> float:\n",
    "        '''(lagacy) 計算這篇報告的 coverage_score，未處理分母為0之情形'''\n",
    "        if not apply_weight:\n",
    "            return len(match_regexs) / self.num_of_used_regex # 無權種的算法，分母是家族 wide\n",
    "        ''' 以下 有權重的算法尚未修改，必出 bug '''\n",
    "        # denominator = sum(self.regexMaster['weight']) # 分母\n",
    "        # numerator = 0 # 分子\n",
    "        # for b, w in zip(self.regexMaster['text'], self.regexMaster['weight']):\n",
    "        #     if b in match_baselines:\n",
    "        #         numerator += w\n",
    "        # return numerator/denominator\n",
    "\n",
    "    def show_result(self, apply_weight: bool=False, base_on_sample = True):\n",
    "        '''(lagacy) print and return result table. baselinse(x) * report(y).'''\n",
    "        column_names = ['report_name','ttl_match','coverage_score']\n",
    "        if base_on_sample:\n",
    "            column_names.extend(list(self.sample.regex_set))\n",
    "        else:\n",
    "            column_names.extend(list(regexMaster.used_regex_set))\n",
    "        result_tbl = pd.DataFrame([[0]*len(column_names)]*len(self.rem_lst), columns=column_names)\n",
    "        for i,rem in enumerate(self.rem_lst):\n",
    "            match_regexes = rem.get_match_regexs() # 這篇報告含有哪些 baseine:set\n",
    "            c_score = self.calc_report_coverage_score(match_regexes, apply_weight=apply_weight)\n",
    "            result_tbl.loc[i,'report_name'] = rem.reportname\n",
    "            result_tbl.loc[i,'ttl_match'] = len(match_regexes)\n",
    "            result_tbl.loc[i,'coverage_score'] = f'{c_score:.4}'\n",
    "            for b in match_regexes:\n",
    "                result_tbl.loc[i,b] = 1\n",
    "            print(rem.reportname, match_regexes)\n",
    "        display(result_tbl)\n",
    "        return result_tbl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Script: 存檔每篇報告的 matched sentence (以樣本的 regex set 為基準)\n",
    "比較樣本間的辨別度，有 n 個樣本，就會跑 n 變，得出 n 個結果 (FanilySet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexMaster.get_obj_by_reg('Memory Address') # None\n",
    "regexMaster.get_obj_by_reg('0x[0-9a-zA-Z]{1,16}') # 0x[0-9a-zA-Z]{8} # return ['Memory Address']\n",
    "\n",
    "import os, psutil\n",
    "def print_mem_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "    print(f\"=== mem_usage: {mem_usage:.2f} MB ===\")  # in MiB \n",
    "\n",
    "def get_mem_usage() -> int:\n",
    "    # process = psutil.Process(os.getpid())\n",
    "    mem_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2\n",
    "    return mem_usage\n",
    "\n",
    "import numpy as np\n",
    "def printStep(steplist: list[str], ref_steps_n=set()):\n",
    "    \"\"\"example str: ' 56. sed     -> open()     -> /etc/rc.local', ref_steps_n 分母/全部的step\"\"\"\n",
    "    steplist = list(steplist)\n",
    "    orders = [int(s.split('.')[0]) for s in steplist]\n",
    "    orders = np.argsort(orders)\n",
    "    for o in orders:\n",
    "        if steplist[o] in ref_steps_n:\n",
    "            print(steplist[o], 'v')\n",
    "        else:\n",
    "            print(steplist[o])\n",
    "    return orders\n",
    "\n",
    "def getStepOrder(steplist: list[str]):\n",
    "    \"\"\"example str: ' 56. sed     -> open()     -> /etc/rc.local', return the step numbers (1~last)\"\"\"\n",
    "    steplist = list(steplist)\n",
    "    orders = [int(s.split('.')[0]) for s in steplist]\n",
    "    orders = np.sort(orders)\n",
    "    return orders\n",
    "\n",
    "def getChangeStepOrder(steplist: list[str], oe: OperationEvaluator):\n",
    "    '''return 含有會造成任何改變的 syscall 的 step (1~last)'''\n",
    "    changeStep = []\n",
    "    for i,s in enumerate(steplist):\n",
    "        syscall = s[2]\n",
    "        if syscall in oe.update_syscall_list:\n",
    "            changeStep.append(i+1)\n",
    "    return changeStep\n",
    "\n",
    "def run_family_set_procedure(sample: Sample, muti_sample:bool=False) -> FamilySet:\n",
    "    # family is global variable\n",
    "    operationEvaluator = OperationEvaluator()\n",
    "    txt_report = \"\"\n",
    "    \n",
    "    fset = FamilySet(family, sample.regexMaster, sample=sample)\n",
    "    for i,rdf in enumerate(xor_report_dfs):\n",
    "        fset.add_rem(rdf, xor_report_names[i])\n",
    "    # result_tbl = fset.show_result(apply_weight=False)\n",
    "    # result_tbl.to_csv(f'{outputfolder}/{family}_{sample.samplename[:3]}_FamilySet_by_Regex.csv', index=False)\n",
    "    # print(f\"Sample {sample.samplename[:3]} has ttl_match {result_tbl['ttl_match'].sum()} on all documents.\") \n",
    "\n",
    "    # Calculate metrics\n",
    "    print_mem_usage()\n",
    "    # for op in sample.OPset:\n",
    "    #     print(f\"{op.object} | {op.object_type}\")\n",
    "    txt_report += f\"asg_object: {sorted(sample.regex_set)}\\n\"\n",
    "    fset.sample.OPset_sysOnly_ordered = [op for op in sample.OPset if op.action in operationEvaluator.update_syscall_list] # UPDATE系統設定的OP\n",
    "    fset.sample.OPset_sysOnly_ordered_index = [sample.OPset_ordered.index(op) for op in fset.sample.OPset_sysOnly_ordered] # no use\n",
    "    fset.sample.ASGstep_sysOnly_ordered_index = getChangeStepOrder(Utility.get_sorted_uni_step(asg), operationEvaluator)\n",
    "    for idx_rem, rem in enumerate(fset.rem_lst):\n",
    "        if rem.reportname == 'Xorddos-Microsoft.csv': # 除錯用\n",
    "            continue\n",
    "        print(f\"Document {rem.reportname:<30} metrics calculating...\")\n",
    "        txt_report += f\"\\nSample {rem.reportname}\\n\"\n",
    "        txt_report += f\"\\tnum of segment in report: {len(rem.sentences)}, {len(rem.matched_sent_id)} of them contain ASG object(s)\\n\"\n",
    "        txt_report += f\"\\tlenght of ctd's OPset is {len(rem.doc_OPset)}\\n\"\n",
    "\n",
    "        # R_malObj 比較物件\n",
    "        # Exp6 改成計算文章中 STobject 的可重複數量，但 memory, ip 等 sink 過的只記數一次\n",
    "        numofSTobject, numofSTobject_sys = 0, 0\n",
    "        counter = rem.STcounter\n",
    "        # 只記數一次的STregex\n",
    "        cntone_regex = ['0x[0-9a-zA-Z]{1,16}', '\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}', '\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}:\\\\d+', ]\n",
    "        if counter:\n",
    "            for reg, cnt in counter.most_common():\n",
    "                if reg in ['port \\\\d+']: # 忽略記數的 (因為他是兩個字，先不處理)\n",
    "                    continue\n",
    "                if reg in cntone_regex:\n",
    "                    numofSTobject += 1\n",
    "                else:\n",
    "                    numofSTobject += cnt\n",
    "                    if '/etc' in reg:\n",
    "                        numofSTobject_sys += cnt\n",
    "        # asg_object = set([op.object for op in sample.OPset]) # dont use this\n",
    "        asg_object = sample.regex_set\n",
    "        ctd_object = set([op.object for op in rem.doc_OPset]) # same as rem.match_regex\n",
    "        if rem.reportname == \"Dofloo-SyscallParty.csv\":\n",
    "            print(\"asg_object =>\", asg_object)\n",
    "            print(\"ctd_object =>\", ctd_object, '\\n')\n",
    "        ctd_object = ctd_object.intersection(asg_object)\n",
    "        numerator = sum([len(regexMaster.get_obj_by_reg(reg)) for reg in ctd_object])\n",
    "        denominator = len(raw_objects) # 全域變數\n",
    "        R_malObj = 0 if denominator == 0 else numerator/denominator\n",
    "        txt_report += f\"\\t#numofSTobject: {numofSTobject}, numofSTobject sysRrc: {numofSTobject_sys}\\n\"\n",
    "        txt_report += f\"\\t#R_malObj\\n\\tnum of ctd objects: {numerator}, num of asg objects: {denominator}. R_malObj is {R_malObj:.4f}\\n\"\n",
    "        txt_report += f\"\\t\\tctd_object: {sorted(ctd_object)}\\n\"\n",
    "        metric = Metric()\n",
    "        metric.numOfSTobj = numofSTobject\n",
    "        metric.numOfSTsys = numofSTobject_sys\n",
    "        metric.setObj(numerator, denominator)\n",
    "        if rem.reportname == \"Dofloo-SyscallParty.csv\":\n",
    "            print(\"regex => objects mapping\")\n",
    "            for reg in ctd_object:\n",
    "                print(reg, '=>', regexMaster.get_obj_by_reg(reg))\n",
    "\n",
    "        # R_malSysObj 比較系統物件\n",
    "        asg_sysobj = list(filter(lambda object: object.find('/etc') != -1, asg_object))\n",
    "        ctd_sysobj = list(filter(lambda object: object.find('/etc') != -1, ctd_object))\n",
    "        numerator = sum([len(regexMaster.get_obj_by_reg(reg)) for reg in ctd_sysobj]) # len(ctd_sysobj)\n",
    "        denominator = sum([len(regexMaster.get_obj_by_reg(reg)) for reg in asg_sysobj]) # len(asg_sysobj)\n",
    "        R_malSysObj = 0 if denominator == 0 else numerator/denominator\n",
    "        txt_report += f\"\\t#R_malSysObj\\n\\tnum of ctd objects: {numerator}, num of asg objects: {denominator}. R_malSysObj is {R_malSysObj:.4f}\\n\"\n",
    "        metric.setObjSys(numerator, denominator)\n",
    "\n",
    "        # R_malOps 比較動作和物件\n",
    "        asg_OPset = list(sample.OPset)\n",
    "        ctd_OPset = list(rem.doc_OPset)\n",
    "        numerator, denominator, hits = 0, len(Utility.get_uni_step(asg)), [] # 0, len(asg_OPset), []\n",
    "        ref_steps = set()\n",
    "        hits: list[tuple[OperationPair, OperationPair]] = []\n",
    "        sys_hits: list[tuple[OperationPair, OperationPair]] = []\n",
    "        txt_report += f\"\\t\\tlen(asg_OPset): {len(asg_OPset)}, len(ctd_OPset): {len(ctd_OPset)}\\n\"\n",
    "        # 每一個 asg_op 跟所有同物件的的 ctd_op 進行 resolve() 比對，來判斷此 asg_op 是否被提及\n",
    "        i = 0\n",
    "        for idx_asg, asg_op in enumerate(asg_OPset): \n",
    "            i += 1\n",
    "            target_obj = asg_op.object\n",
    "            ctdSameObjOpsIdx = [i for i, x in enumerate(ctd_OPset) if x.object == target_obj]\n",
    "            # ctdSameObjOps = [x for x in ctd_OPset if x.object == target_obj]\n",
    "            for idx in ctdSameObjOpsIdx:\n",
    "                pass\n",
    "                # mem_before_create_lst = get_mem_usage()\n",
    "                # print(\"\\tbefore resolve\", mem_before_create_lst)\n",
    "                entityType = asg_op.object_type # get_object_type(asg_op.object)\n",
    "                (hit, isSysChange, altVerb) = operationEvaluator.resolve(entityType, asg_op.action, ctd_OPset[idx].action, \n",
    "                                                                use_bert=True, sentence=ctd_OPset[idx].original_sentence)\n",
    "                # # print_mem_usage()\n",
    "                # mem_after_create_lst = get_mem_usage()\n",
    "                # # print(f\"\\t=== diff of mem_usage calling resolve(): {mem_after_create_lst - mem_before_create_lst:.2f}  ===\")\n",
    "\n",
    "                if hit:\n",
    "                    # numerator += 1\n",
    "                    steps = Utility.query_origin_steplist(asg, asg_op.action, target_obj)\n",
    "                    if steps:\n",
    "                        ref_steps.update(steps) # match asg steps 會重複(?)不能直接加，用set儲存step string\n",
    "                    ctd_OPset[idx].altVerb = altVerb # altVerb is string if OoV and found an alt, else None\n",
    "                    hits.append((asg_OPset[idx_asg], ctd_OPset[idx]))\n",
    "                    fset.rem_lst[idx_rem].match_doc_OPset.add(ctd_OPset[idx])\n",
    "                    try:\n",
    "                        fset.rem_lst[idx_rem].matched_syscalls[(ctd_OPset[idx].action, target_obj)].append(asg_op.action) \n",
    "                    except:\n",
    "                        fset.rem_lst[idx_rem].matched_syscalls[(ctd_OPset[idx].action, target_obj)] = [asg_op.action] # key:(v,r), val:syscall_list\n",
    "\n",
    "                    # 篩選出系統物件的動作\n",
    "                    if isSysChange:\n",
    "                        sys_hits.append((asg_OPset[idx_asg], ctd_OPset[idx]))\n",
    "\n",
    "                    # 紀錄CTD的生命週期 (ASG_OP提及順序)\n",
    "                    step_num = sample.OPset_ordered.index(asg_op) # index of step, throw ValueError if not found\n",
    "                    fset.rem_lst[idx_rem].OPset_order_index.append(step_num)\n",
    "                    break\n",
    "        numerator = len(ref_steps)\n",
    "        R_malOps = 0 if denominator == 0 else numerator/denominator\n",
    "        txt_report += f\"\\t#R_malOps\\n\\tnum of matched asg op: {numerator}, num of asg op: {denominator}. R_malOps is {R_malOps:.4f}\\n\"\n",
    "        txt_report += f\"\\t\\trefered lifecycle: {sorted(fset.rem_lst[idx_rem].OPset_order_index)}\\n\"\n",
    "        metric.setOp(numerator, denominator)\n",
    "        fset.rem_lst[idx_rem].ASGstep_order_index = getStepOrder(ref_steps)\n",
    "        if rem.reportname == \"Dofloo-SyscallParty.csv\":\n",
    "            print(\"\\n==== R_malOps ====\")\n",
    "            printStep(ref_steps)\n",
    "\n",
    "        # R_malChangeOps 篩選出系統物件的動作\n",
    "        # cando: 加上 OPMode的考量，為class OP加兩個mode asg_op_mode, ctd_op_mode。目前直接用call nlp class 的 method判別。\n",
    "        # numerator = len(sys_hits)\n",
    "        sys_asg_OPset = [op for op in asg_OPset if op.action in operationEvaluator.update_syscall_list ]\n",
    "        # print('sys_asg_OPset is unique:', len(sample.OPset_ordered) == len(set(sample.OPset_ordered))) # 元速度重複沒錯，可能是 index() 的問題\n",
    "        ref_steps_n = set()\n",
    "        for op, _ in sys_hits:\n",
    "            steps = Utility.query_origin_steplist(asg, op.action, op.object)\n",
    "            ref_steps_n.update(steps)\n",
    "        numerator = len(ref_steps_n)\n",
    "        ref_steps_d = set()\n",
    "        for op in sys_asg_OPset:\n",
    "            steps = Utility.query_origin_steplist(asg, op.action, op.object)\n",
    "            ref_steps_d.update(steps)\n",
    "        denominator = len(ref_steps_d)\n",
    "        if rem.reportname == \"Dofloo-SyscallParty.csv\":\n",
    "            print(\"\\n==== R_malChangeOps ====\")\n",
    "            printStep(ref_steps_d, ref_steps_n)\n",
    "        # denominator = len(sys_asg_OPset)\n",
    "        R_malChangeOps = 0 if denominator == 0 else numerator/denominator\n",
    "        txt_report += f\"\\t#R_malChangeOps\\n\\tnum of matched asg op: {numerator}, num of asg op: {denominator}. R_malChangeOps is {R_malChangeOps:.4f}\\n\"\n",
    "        metric.setOpSys(numerator, denominator)\n",
    "\n",
    "        # 紀錄CTD的生命週期 (OP提及順序)\n",
    "        fset.rem_lst[idx_rem].SysASGstep_order_index = getStepOrder(ref_steps_n)\n",
    "        fset.rem_lst[idx_rem].SysOPset_order_index.clear()\n",
    "        for asg_op , ctd_op in sys_hits:\n",
    "            step_num = sample.OPset_ordered.index(asg_op) # step index , throw ValueError if not found\n",
    "            fset.rem_lst[idx_rem].SysOPset_order_index.append(step_num)\n",
    "        txt_report += f\"\\t\\tref-sys lifecycle: {fset.rem_lst[idx_rem].SysOPset_order_index}\\n\"\n",
    "\n",
    "        if hits:\n",
    "            txt_report += \"\\n\\thits\\n\"\n",
    "            hits.sort(key=lambda tup: str(tup[0]), reverse=False)\n",
    "            for asg_op, ctd_op in hits:\n",
    "                txt_report += f\"\\t{asg_op}, {ctd_op.getSentStr()}\\n\"\n",
    "        if sys_hits:\n",
    "            txt_report += \"\\n\\tsys_hits\\n\"\n",
    "            sys_hits.sort(key=lambda tup: str(tup[0]), reverse=False)\n",
    "            for asg_op, ctd_op in sys_hits:\n",
    "                txt_report += f\"\\t{asg_op}, {ctd_op.getSentStr()}\\n\"\n",
    "        fset.rem_lst[idx_rem].metric = metric\n",
    "        # print_mem_usage()\n",
    "        # del asg_OPset, ctd_OPset, hits, sys_hits\n",
    "    txt_report += f\"\\n\\nOperationPair that changes system resources:\\n{sys_asg_OPset}\\n\\n\"\n",
    "    txt_report += json.dumps(regex_match_file, indent=4, sort_keys=True)\n",
    "\n",
    "    if muti_sample:\n",
    "        pass\n",
    "    filename = f\"./result/metric_{family.lower()}.txt\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(txt_report) \n",
    "    return fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_match_sent_to_excel(fset: FamilySet, sample_name=None):\n",
    "    columns = ['report','regex','matched word','sentence number','sentence']\n",
    "    if sample_name:\n",
    "        output_xlsx = f'{outputfolder}/{family}_{sample_name[:3]}_report_match_sent.csv'\n",
    "    else:\n",
    "        output_xlsx = f'{outputfolder}/{family}_union_report_match_sent.csv'\n",
    "    has_match = sum([len(rem.get_match_regexs()) for rem in fset.rem_lst])\n",
    "    if has_match == 0:\n",
    "        print('no matches in CTI reports') # with open 一定要寫入，若全空則直接不開檔\n",
    "        return\n",
    "    # with pd.ExcelWriter(output_xlsx, engine='openpyxl') as writer:\n",
    "    \n",
    "    # 遍歷報告，一個 rem: ReportEvalModel 代表一篇報告\n",
    "    csv_data = []\n",
    "    match_sentence_ttlcnt = 0\n",
    "    for rem in fset.rem_lst:\n",
    "        reportname = rem.reportname.split('.')[0]\n",
    "        if len(rem.get_match_regexs()) == 0: # 如果報告中無 regex 跳過不紀錄\n",
    "            continue\n",
    "        # sheet_data = [] # shape = columns_len * match_sent_len\n",
    "        sent_df = rem.get_match_sentences()\n",
    "        sent_content_lst = rem.sentences['Content'] # 報告中的每個句子\n",
    "        match_sentence_ttlcnt += sent_df['match'].sum()\n",
    "\n",
    "        # 遍歷每個含有 regex 的句子\n",
    "        for sid, row in sent_df.iterrows():\n",
    "            if row['match'] == 0:\n",
    "                continue\n",
    "            row.drop('match', inplace=True)\n",
    "            row = row[row > 0]\n",
    "            # print(row)\n",
    "            # 考量每個句子可能含有多個 regex，故需寫成多行\n",
    "            for i, v in row.items():\n",
    "                insert_data = dict().fromkeys(columns)\n",
    "                insert_data['report'] = reportname\n",
    "                insert_data['regex'] = i\n",
    "                insert_data['matched word'] = rem.get_match_word(sid, i)\n",
    "                insert_data['sentence number'] = sid + 1\n",
    "                insert_data['sentence'] = str(sent_content_lst[sid]).strip()\n",
    "                # sheet_data.append(insert_data)\n",
    "                csv_data.append(insert_data)\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    # print(df)\n",
    "    df.to_csv(output_xlsx, index=False)\n",
    "\n",
    "            # 輸出 csv\n",
    "            \n",
    "            # 輸出 excel sheet\n",
    "            # print(rem.reportname,'has', len(sheet_data),'matches')\n",
    "            # output_sheet = pd.DataFrame(sheet_data)\n",
    "            # # output_sheet.style.set_properties(subset=['sentence'])\n",
    "            # styler = Styler(horizontal_alignment='left', vertical_alignment='top')\n",
    "            # sf = StyleFrame(output_sheet, styler)\n",
    "            # sf = sf.set_column_width(columns=['baseline'], width=20.0)\n",
    "            # sf = sf.set_column_width(columns=['sentence number'], width=15.0)\n",
    "            # sf = sf.set_column_width(columns=['sentence'], width=80.0)\n",
    "            # sf.to_excel(writer, sheet_name=rem.reportname, index=False) #.save()\n",
    "            # # output_sheet.to_excel(writer, sheet_name=rem.reportname, index=False)\n",
    "    return match_sentence_ttlcnt\n",
    "\n",
    "# 此行會執行並複寫 excel，執行完後要手動調整行距格式，小心使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== mem_usage: 779.64 MB ===\n",
      "Document Conti.csv                      metrics calculating...\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    # print(len(sample.OPset)) # 30\n",
    "    # print(len(sample.OPset_ordered)) # 30\n",
    "    # print(set(sample.OPset) - set(sample.OPset_ordered)) # 相減是空的set 都OK\n",
    "    fset = run_family_set_procedure(sample)\n",
    "    # match_sentence_ttlcnt = save_match_sent_to_excel(fset, sample.samplename)\n",
    "    # print(f'match_sentence_ttlcnt is {match_sentence_ttlcnt}\\n---\\n')\n",
    "\n",
    "import numpy as np\n",
    "result_table = []\n",
    "result_header = ['Γ_obj','Γ_obj','Γ_rsc','Γ_rsc','Ф_op','Ф_op','Ф_sys','Ф_sys']\n",
    "\n",
    "for rid, report in enumerate(xor_report_names):\n",
    "    # view result of different sample under each document\n",
    "    reportname = report.split('.')[0]\n",
    "    reportname = reportname.replace(f\"{family}-\", '')\n",
    "    reportname = reportname.replace('.csv', '')\n",
    "    reportname = f'D{rid+1} {reportname}'\n",
    "\n",
    "    # each sample contains its ASG data\n",
    "    samplename = f\"S{fset.sample.samplename[:3]}\"\n",
    "\n",
    "    # metrics for rid, sid\n",
    "    rem = fset.rem_lst[rid]\n",
    "    s_Obj = f\"{rem.metric.getMetricObj():.4f}\"\n",
    "    s_Obj_fraction = f\"{rem.metric.objN}/{rem.metric.objD}\"\n",
    "    s_ObjSys = f\"{rem.metric.getMetricObjSys():.4f}\"\n",
    "    s_ObjSys_fraction = f\"{rem.metric.objSysN}/{rem.metric.objSysD}\"\n",
    "    s_Op = f\"{rem.metric.getMetricOp():.4f}\"\n",
    "    s_Op_fraction = f\"{rem.metric.opN}/{rem.metric.opD}\"\n",
    "    s_OpSys = f\"{rem.metric.getMetricOpSys():.4f}\"\n",
    "    s_OpSys_fraction = f\"{rem.metric.opSysN}/{rem.metric.opSysD}\"\n",
    "\n",
    "    result_sample = [reportname, \\\n",
    "                    samplename, \\\n",
    "                    s_Obj, s_Obj_fraction, s_ObjSys, s_ObjSys_fraction,\\\n",
    "                    s_Op, s_Op_fraction, s_OpSys, s_OpSys_fraction]\n",
    "    result_table.append(result_sample)\n",
    "result_table = np.array(result_table)\n",
    "result_table = result_table.T\n",
    "result_table = pd.DataFrame(result_table)\n",
    "# display(result_table) # 顯示計分數改用下方的 block"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Script: 將 metrics 存進 csv 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns_for_metrics(mdf:pd.DataFrame):\n",
    "    mdf['numOfSTobj'] = '' # 文章中的STobj數量 (sink mem&net)\n",
    "    mdf['numOfSTsys'] = ''\n",
    "    mdf['objN'] = ''  # 物件分子\n",
    "    mdf['objD'] = ''  # 物件分母\n",
    "    mdf['objSysN'] = '' # 系統設定檔物件分子\n",
    "    mdf['objSysD'] = '' # 系統設定檔物件分母\n",
    "    mdf['opN'] = ''     # 動作和物件分子\n",
    "    mdf['opD'] = ''     # 動作和物件分母\n",
    "    mdf['opSysN'] = ''  # 動作和系統物件分子\n",
    "    mdf['opSysD'] = ''  # 動作和系統物件分母\n",
    "    mdf['obj'] = ''\n",
    "    mdf['objSys'] = ''\n",
    "    mdf['op'] = ''\n",
    "    mdf['opSys'] = ''\n",
    "    mdf.to_csv('./result/_info.csv', index=False)\n",
    "# mdf = pd.read_csv('./result/_info.csv')\n",
    "# create_columns_for_metrics(mdf)           # should not execute, will erease all the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>DocId</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Txtname</th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>objN</th>\n",
       "      <th>objD</th>\n",
       "      <th>objSysN</th>\n",
       "      <th>objSysD</th>\n",
       "      <th>opN</th>\n",
       "      <th>opD</th>\n",
       "      <th>opSysN</th>\n",
       "      <th>opSysD</th>\n",
       "      <th>obj</th>\n",
       "      <th>objSys</th>\n",
       "      <th>op</th>\n",
       "      <th>opSys</th>\n",
       "      <th>numOfSTobj</th>\n",
       "      <th>numOfSTsys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Conti</td>\n",
       "      <td>D9,1</td>\n",
       "      <td>analysis</td>\n",
       "      <td>Conti</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Family DocId     Genre Txtname Source Title  objN  objD  objSysN  objSysD  \\\n",
       "46  Conti  D9,1  analysis   Conti                0.0   6.0      0.0      0.0   \n",
       "\n",
       "    opN   opD  opSysN  opSysD  obj  objSys   op  opSys  numOfSTobj  numOfSTsys  \n",
       "46  0.0  11.0     0.0     0.0  0.0     0.0  0.0    0.0         0.0         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_report_id(reportname:str, mdf:pd.DataFrame) -> str:\n",
    "    ''' Luabot-malwaremustdie -> 'D5,2' '''\n",
    "    reportname = reportname.replace('.csv','')\n",
    "    reportname = reportname.replace('.txt','')\n",
    "    mdf = mdf[mdf['Txtname'] == reportname]\n",
    "    mdf = mdf.reset_index()\n",
    "    if len(mdf) == 1:\n",
    "        return mdf.loc[0, 'DocId']\n",
    "    return None\n",
    "def get_report_index(reportname:str, mdf:pd.DataFrame) -> int:\n",
    "    ''' Luabot-malwaremustdie -> 30 '''\n",
    "    reportname = reportname.replace('.csv','')\n",
    "    reportname = reportname.replace('.txt','')\n",
    "    ids = mdf.index[mdf['Txtname'] == reportname].tolist()\n",
    "    try:\n",
    "        return ids[0]\n",
    "    except:\n",
    "        print(f\"{reportname} index not found...\")\n",
    "        return None\n",
    "\n",
    "# load csv that store results\n",
    "mdf = pd.read_csv('./result/_info.csv')\n",
    "# mdf.loc[30, 'objN'], mdf.loc[30, 'objD'] = 1, 2\n",
    "# mdf.loc[29:30,:]\n",
    "\n",
    "ids = []\n",
    "for rem in fset.rem_lst:\n",
    "    m = rem.metric\n",
    "    idx = get_report_index(rem.reportname, mdf)\n",
    "    ids.append(idx)\n",
    "    mdf.loc[idx, 'numOfSTobj'], mdf.loc[idx, 'numOfSTsys'] = m.numOfSTobj, m.numOfSTsys\n",
    "    mdf.loc[idx, 'objN'], mdf.loc[idx, 'objD'], mdf.loc[idx, 'obj'] = m.objN, m.objD, m.getMetricObj()\n",
    "    mdf.loc[idx, 'objSysN'], mdf.loc[idx, 'objSysD'], mdf.loc[idx, 'objSys'] = m.objSysN, m.objSysD, m.getMetricObjSys()\n",
    "    mdf.loc[idx, 'opN'], mdf.loc[idx, 'opD'], mdf.loc[idx, 'op'] = m.opN, m.opD, m.getMetricOp()\n",
    "    mdf.loc[idx, 'opSysN'], mdf.loc[idx, 'opSysD'], mdf.loc[idx, 'opSys'] = m.opSysN, m.opSysD, m.getMetricObj()\n",
    "display(mdf.loc[sorted(ids),:].sort_values(by=['DocId']))\n",
    "mdf.to_csv('./result/_info.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Script: draw Lifecycle diagram\n",
    "- 兩個 traces (legend) 一般的 OP 和 ChangeSys OP。分兩個顏色，不重疊。\n",
    "- x: [a,a,a,a,b,b,b,c,c,c] 不同 report 的 step 可以放同一個 list，因為屬於同個 trace。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source domian of report not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luweb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\io\\_renderers.py:7: DeprecationWarning:\n",
      "\n",
      "The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "opacity": 0
         },
         "type": "scatter",
         "x": [
          0
         ],
         "y": [
          "Conti (0)"
         ]
        },
        {
         "marker": {
          "color": "darkorange",
          "size": 10
         },
         "mode": "markers",
         "name": "Normal ASG step",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "y": [
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)",
          "ASG (11)"
         ]
        },
        {
         "marker": {
          "color": "blue",
          "size": 10
         },
         "mode": "markers",
         "name": "Change system state ASG step",
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Attackflow Diagram of Attack Behavior in Document (Conti)"
        },
        "xaxis": {
         "title": {
          "text": "ASG steps (in order)"
         }
        },
        "yaxis": {
         "title": {
          "text": "Malware Document"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def symmetric_difference(list1: list, list2: list) -> list:\n",
    "    ''' return list1 - list2. '''\n",
    "    s = set(list2)\n",
    "    temp3 = [x for x in list1 if x not in s]\n",
    "    return temp3\n",
    "\n",
    "def draw_lifecycle(fset:FamilySet):\n",
    "    familname = fset.familyname\n",
    "    # reportnames = [rem.reportname for rem in fset.rem_lst if len(rem.match_regex)]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    x, y = [], []\n",
    "    x_sys, y_sys = [], []\n",
    "    empty_columns = []\n",
    "\n",
    "    for i, rem in enumerate(fset.rem_lst):\n",
    "        numOfDot = len(rem.ASGstep_order_index)\n",
    "        reportname = rem.reportname\n",
    "        try:\n",
    "            reportname = rem.reportname.split('.')[0]\n",
    "            reportname = reportname.split('-')[1]\n",
    "        except:\n",
    "            print('source domian of report not found.')\n",
    "            pass\n",
    "        if reportname == 'Ms':\n",
    "            reportname = 'Microsoft'\n",
    "        reportname += f' ({numOfDot})'\n",
    "        if len(rem.ASGstep_order_index) == 0:\n",
    "            empty_columns.append(reportname)\n",
    "            continue\n",
    "        x_sys.extend(rem.SysASGstep_order_index) # 改變系統設定檔的 OP (這個變數有問題!!!)\n",
    "        y_sys.extend([reportname] * len(rem.SysASGstep_order_index))\n",
    "        current_x_normal = symmetric_difference(rem.ASGstep_order_index, rem.SysASGstep_order_index) # 一般的/其餘的 OP\n",
    "        # print(reportname, 'numOfDot', numOfDot, 'rem.ASGstep_order_index', rem.ASGstep_order_index)\n",
    "        # print('x_normal', current_x_normal, 'x_sys', rem.SysASGstep_order_index)\n",
    "        x.extend(current_x_normal)\n",
    "        y.extend([reportname] * len(current_x_normal))\n",
    "        pass\n",
    "    # todo: add baseline's lifecycle\n",
    "    num_allstep = len(set(fset.sample.step_list))\n",
    "    rowname = f'ASG ({num_allstep})'\n",
    "    current_x_system = fset.sample.ASGstep_sysOnly_ordered_index # fset.sample.OPset_sysOnly_ordered_index\n",
    "    current_x_normal = symmetric_difference(list(range(num_allstep)), current_x_system) # all steps - sysobj steps\n",
    "    # print(sorted(current_x_system)) # 只能放UPDATE的，OPEN/READ不能喔\n",
    "    x_sys.extend(current_x_system)\n",
    "    y_sys.extend([rowname] * len(current_x_system)) \n",
    "    x.extend(current_x_normal)\n",
    "    y.extend([rowname] * len(current_x_normal))\n",
    "    # print(rowname, len(fset.sample.OPset), len(current_x_system), len(current_x_normal))\n",
    "\n",
    "    # for empty_columns when report has no OPs\n",
    "    for empty_col in empty_columns:\n",
    "        fig.add_trace(go.Scatter(x=[0,], y=[empty_col,], marker=dict(opacity=0)))\n",
    "    \n",
    "    # normal OPs\n",
    "    x = [idx+1 for idx in x] # add 1 to each asg index\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        marker=dict(color=\"darkorange\", size=10),\n",
    "        mode=\"markers\",\n",
    "        name=\"Normal ASG step\", # Normal Operation Pair\n",
    "    ))\n",
    "\n",
    "    # changeSysObj OPs\n",
    "    x_sys = x = [idx+1 for idx in x_sys]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_sys,\n",
    "        y=y_sys,\n",
    "        marker=dict(color=\"blue\", size=10),\n",
    "        mode=\"markers\",\n",
    "        name=\"Change system state ASG step\", # Change SR Operation Pair\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(title=f\"Attackflow Diagram of Attack Behavior in Document ({familname})\",\n",
    "                    xaxis_title=\"ASG steps (in order)\",\n",
    "                    yaxis_title=\"Malware Document\")\n",
    "    fig.show()\n",
    "\n",
    "    if not os.path.exists(\"imgs\"):\n",
    "        os.mkdir(\"imgs\")\n",
    "    # fig.write_image(f\"./imgs/{familname}_lifecycle.png\") # bug -> no responce\n",
    "    # plotly.offline.plot(fig, filename=f\"./imgs/{familname}_lifecycle.html\", auto_open=False)\n",
    "    pass\n",
    "\n",
    "draw_lifecycle(fset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only these syscall will change system config files: ['write', 'rename', 'fchmod', 'chmod', 'lchmod']\n",
    "# operationEvaluator = OperationEvaluator()\n",
    "# print(operationEvaluator.update_syscall_list) \n",
    "# del operationEvaluator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Script: draw ASG & CTD's OP graph\n",
    "- 完整的 ASG OPset graph\n",
    "- 每篇報告的 CTD OPset (完整和matched兩種)，以及對應部分的 ASG。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c', 'd']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = ['a','b','c','d','e']\n",
    "[b[i] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n",
       " -->\n",
       "<!-- Title: Conti_asg_OPset Pages: 1 -->\n",
       "<svg width=\"737pt\" height=\"131pt\"\n",
       " viewBox=\"0.00 0.00 737.32 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n",
       "<title>Conti_asg_OPset</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-127 733.32,-127 733.32,4 -4,4\"/>\n",
       "<!-- Start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Start</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"327.32\" cy=\"-105\" rx=\"77.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"327.32\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Malware (Subject)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"264.32\" cy=\"-18\" rx=\"112.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.32\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0x[0&#45;9a&#45;zA&#45;Z]{1,16} (mem)</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.6,-101.05C161.07,-96.74 19.62,-87.16 3.32,-69 -1.13,-64.04 -1.07,-59.02 3.32,-54 21.93,-32.74 83.41,-23.85 142.03,-20.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.37,-23.82 152.16,-19.78 141.98,-16.84 142.37,-23.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.32\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4.munmap()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.26,-102.9C190.39,-100.22 114.27,-92.17 94.32,-69 71.33,-42.29 102.97,-29.47 144.94,-23.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.45,-26.93 154.92,-22.18 144.56,-19.98 145.45,-26.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.82\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.arch_prctl()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263.46,-94.75C233.84,-89.02 203.22,-80.54 194.32,-69 185.26,-57.25 193.78,-47.08 207.6,-39.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.49,-42.01 216.78,-34.32 206.29,-35.79 209.49,-42.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.32\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8.futex()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.54,-89.53C278.75,-84.42 270.52,-77.7 265.32,-69 261.35,-62.34 260.02,-54.23 259.99,-46.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"263.49,-46.57 260.61,-36.37 256.5,-46.14 263.49,-46.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"316.82\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6.set_robust_list()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.82,-87.98C366.3,-78.36 376.77,-65.76 368.32,-54 363.03,-46.64 356.12,-40.8 348.36,-36.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"349.77,-32.97 339.29,-31.46 346.54,-39.18 349.77,-32.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"391.82\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.brk()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M381.82,-92.21C407.32,-84.11 429.32,-71.61 415.32,-54 407.56,-44.24 385.63,-36.95 360.8,-31.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.27,-28.16 350.78,-29.62 359.89,-35.03 361.27,-28.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.82\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5.set_tid_address()</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;1 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Start&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M403.06,-101.11C454.71,-97.36 516.65,-88.75 533.32,-69 537.63,-63.91 537.72,-59.01 533.32,-54 522.59,-41.77 445.04,-32.55 375.96,-26.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"376.09,-23.15 365.83,-25.8 375.51,-30.12 376.09,-23.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"571.32\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.mprotect()</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"677.32\" cy=\"-18\" rx=\"51.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"677.32\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.*/dracut/.*</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Start&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M400.7,-99.21C471.58,-93.81 573.46,-83.81 610.32,-69 625.97,-62.71 641.22,-51.83 653.2,-41.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"655.69,-44.3 660.94,-35.1 651.1,-39.02 655.69,-44.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"664.32\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7.access()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x1899fc3fa60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "class ItemMapper:\n",
    "    def __init__(self) -> None:\n",
    "        self.mapper = {}\n",
    "        self.index_counter:int = 1\n",
    "        pass\n",
    "    def addItem(self, item:str) -> str:\n",
    "        # item = self.prettifyName(item) # 先不在這做~\n",
    "        if item in self.mapper.keys():\n",
    "            return self.mapper.get(item)\n",
    "        self.mapper[item] = str(self.index_counter)\n",
    "        self.index_counter += 1\n",
    "        return str(self.index_counter - 1)\n",
    "    def getSymbol(self, item:str):\n",
    "        return self.mapper.get(item, None)\n",
    "\n",
    "def draw_asg_op_graph(asg_OPset: list[OperationPair], family=None):\n",
    "    dot = graphviz.Digraph(f'{family}_asg_OPset', comment='The Operational Pair Graph') \n",
    "    dot.node('Start', label=\"Malware (Subject)\")\n",
    "    mapper = ItemMapper()\n",
    "    for op in asg_OPset:\n",
    "        node_id = mapper.addItem(prettifyName(op.object))\n",
    "        # dot.node(node_id, label=op.object)\n",
    "        dot.node(node_id, label=prettifyName(op.object)) # rename partial regex\n",
    "        if op.action:\n",
    "            dot.edge('Start', node_id, label=f\"{op.step_number}.{op.action}()\") # syscall have braces end\n",
    "\n",
    "    # dot.graph_attr.update(ratio=\"0.4\")\n",
    "    u = dot.unflatten(stagger=3, fanout=True)\n",
    "    display(u)\n",
    "    del mapper\n",
    "    return u\n",
    "\n",
    "def draw_ctd_op_graph(fset:FamilySet):\n",
    "    for rem in fset.rem_lst:\n",
    "        # doc_OPset\n",
    "        if rem.doc_OPset is None or len(rem.doc_OPset) == 0:\n",
    "            continue\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.node('Start', label=\"Malware (Subject)\")\n",
    "        mapper = ItemMapper()\n",
    "        for op in rem.doc_OPset:\n",
    "            node_id = mapper.addItem(op.object)\n",
    "            dot.node(node_id, label=prettifyName(op.object))\n",
    "            if op.action:\n",
    "                dot.edge('Start', node_id, label=f\"{op.step_number}.{op.action}\")\n",
    "        print(f\"{rem.reportname} raw doc OPset\")\n",
    "        display(dot)\n",
    "        del mapper\n",
    "\n",
    "        # match_doc_OPset\n",
    "        if rem.match_doc_OPset is None or len(rem.match_doc_OPset) == 0:\n",
    "            continue\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.node('Start', label=\"Malware (Subject)\")\n",
    "        mapper = ItemMapper()\n",
    "        for op in rem.match_doc_OPset:\n",
    "            node_id = mapper.addItem(op.object)\n",
    "            dot.node(node_id, label=prettifyName(op.object))\n",
    "            if op.action:\n",
    "                label = f\"{op.step_number}.{op.action}/{op.altVerb}\" if op.altVerb else f\"{op.step_number}.{op.action}\"\n",
    "                dot.edge('Start', node_id, label=label)\n",
    "        print(f\"{rem.reportname} matched doc OPset\")\n",
    "        display(dot)\n",
    "        del mapper\n",
    "\n",
    "        # match_ASG_OPset\n",
    "        if rem.OPset_order_index is None or len(rem.OPset_order_index) == 0:\n",
    "            continue\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.node('Start', label=\"Malware (Subject)\")\n",
    "        mapper = ItemMapper()\n",
    "        for op in [fset.sample.OPset_ordered[i] for i in rem.OPset_order_index]:\n",
    "            node_id = mapper.addItem(op.object)\n",
    "            dot.node(node_id, label=prettifyName(op.object))\n",
    "            if op.action:\n",
    "                dot.edge('Start', node_id, label=f\"{op.step_number}.{op.action}()\")\n",
    "        print(f\"matched ASG OPset for doc {rem.reportname}\")\n",
    "        display(dot)\n",
    "        del mapper\n",
    "    return\n",
    "\n",
    "opset_for_ppt, _ = construct_sample_OPset(asg.step_list, regexMaster, draw_memory_etc=True)\n",
    "# draw_asg_op_graph(sample.OPset, family=family)\n",
    "draw_asg_op_graph(opset_for_ppt, family=family)\n",
    "draw_ctd_op_graph(fset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(sample.OPset)\n",
    "\n",
    "# for op in sample.OPset:\n",
    "#     if op.object_type == 'MEM':\n",
    "#         print(type(op), op, op.object) \n",
    "    # break\n",
    "\n",
    "# for op in opset_for_ppt:\n",
    "    # print(type(op), op)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Script: print matched sentence for specific document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存檔所有 doc_OPset\n",
    "def save_docOPset(fset: FamilySet) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for idx_rem, rem in enumerate(fset.rem_lst):\n",
    "        ctd_opset:list[OperationPair] = list(rem.doc_OPset)\n",
    "        # print(rem.matched_syscalls)\n",
    "        for op in ctd_opset:\n",
    "            try:\n",
    "                res = rem.matched_syscalls[(op.action, op.object)]\n",
    "                a_syscalls = \" \".join([f\"{s}()\" for s in res])\n",
    "            except:\n",
    "                a_syscalls = None\n",
    "            data.append({\n",
    "                'report': rem.reportname,\n",
    "                'word': op.original_object,\n",
    "                'verb': f\"{op.action}/{op.altVerb}\" if op.altVerb else op.action,\n",
    "                'objectType': op.object_type,\n",
    "                'prettyReg': prettifyName(op.object),\n",
    "                'match': 1 if op in rem.match_doc_OPset else 0, # verb 是否有比對到 syscall\n",
    "                'label': 1 if op in rem.match_doc_OPset else 0, # 人工標記的標籤 暫時先跟系統判斷一樣\n",
    "                'asgSyscall': a_syscalls,                       # matched 到的動詞\n",
    "                'sentence': \" \".join(op.original_sentence.splitlines()) if op.original_sentence else None # flatten the sentence segment\n",
    "            })\n",
    "    # print(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by=['report','objectType','prettyReg'])\n",
    "    df.to_csv(f'./result/00_{family}_docOPset.csv', index=False)\n",
    "    return df\n",
    "\n",
    "df = save_docOPset(fset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df[df['report'] == 'Dofloo-SyscallParty.csv']['sentence'].unique()\n",
    "len(df_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPT Data: 挑選一篇目標文件，列出 ST 和 OP 資料，以便作為簡報內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Token data: (id#2 Dofloo-SyscallParty.csv)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prettyReg</th>\n",
       "      <th>word</th>\n",
       "      <th>objectType</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/etc/init\\.d/.*</td>\n",
       "      <td>/etc/init.d/boot.local</td>\n",
       "      <td>FILE</td>\n",
       "      <td>Persistence Persistence is achieved by the mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/etc/rc\\.local</td>\n",
       "      <td>/etc/rc.local</td>\n",
       "      <td>FILE</td>\n",
       "      <td>The /etc/rc.local will execute certain command...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/etc/rc\\.local</td>\n",
       "      <td>/etc/rc.local</td>\n",
       "      <td>FILE</td>\n",
       "      <td>Persistence Persistence is achieved by the mal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/etc/rc\\.local</td>\n",
       "      <td>/etc/rc.local</td>\n",
       "      <td>FILE</td>\n",
       "      <td>(there are several string operations, such as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/proc/net/dev</td>\n",
       "      <td>/proc/net/dev</td>\n",
       "      <td>FILE</td>\n",
       "      <td>The way the malware gets information regarding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/proc/self</td>\n",
       "      <td>/proc/self/exe</td>\n",
       "      <td>FILE</td>\n",
       "      <td>The main method then branches to function name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0x1380</td>\n",
       "      <td>MEM</td>\n",
       "      <td>We then read data from the C2, but first, we z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0x13DEC</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Nice, so now you're an ARM expert we can conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>vaddr=0x00013dec</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Which gives us the following output:  vaddr=0x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0xCA1C)</td>\n",
       "      <td>MEM</td>\n",
       "      <td>The procedure ConnectServer (which is at 0xCA1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0xC1FC8</td>\n",
       "      <td>MEM</td>\n",
       "      <td>We pass in the first parameter in the register...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0xCBD4</td>\n",
       "      <td>MEM</td>\n",
       "      <td>For those not familiar with ARM, the beq instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "      <td>0xB654</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Diving into ServerConnectCli..  ServerConnectC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ip_addr/ip_addr:port/port</td>\n",
       "      <td>61.147.91.53</td>\n",
       "      <td>NET</td>\n",
       "      <td>We pass in the first parameter in the register...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>^sed$</td>\n",
       "      <td>sed</td>\n",
       "      <td>PROC</td>\n",
       "      <td>A string is formatted and the sed program is c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>^sed$</td>\n",
       "      <td>sed</td>\n",
       "      <td>PROC</td>\n",
       "      <td>(there are several string operations, such as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    prettyReg                    word objectType  \\\n",
       "7             /etc/init\\.d/.*  /etc/init.d/boot.local       FILE   \n",
       "9              /etc/rc\\.local           /etc/rc.local       FILE   \n",
       "10             /etc/rc\\.local           /etc/rc.local       FILE   \n",
       "15             /etc/rc\\.local           /etc/rc.local       FILE   \n",
       "11              /proc/net/dev           /proc/net/dev       FILE   \n",
       "5                  /proc/self          /proc/self/exe       FILE   \n",
       "6   0x[0-9a-zA-Z]{1,16} (mem)                  0x1380        MEM   \n",
       "8   0x[0-9a-zA-Z]{1,16} (mem)                 0x13DEC        MEM   \n",
       "12  0x[0-9a-zA-Z]{1,16} (mem)        vaddr=0x00013dec        MEM   \n",
       "13  0x[0-9a-zA-Z]{1,16} (mem)                 0xCA1C)        MEM   \n",
       "16  0x[0-9a-zA-Z]{1,16} (mem)                 0xC1FC8        MEM   \n",
       "17  0x[0-9a-zA-Z]{1,16} (mem)                  0xCBD4        MEM   \n",
       "19  0x[0-9a-zA-Z]{1,16} (mem)                  0xB654        MEM   \n",
       "14  ip_addr/ip_addr:port/port            61.147.91.53        NET   \n",
       "4                       ^sed$                     sed       PROC   \n",
       "18                      ^sed$                     sed       PROC   \n",
       "\n",
       "                                             sentence  \n",
       "7   Persistence Persistence is achieved by the mal...  \n",
       "9   The /etc/rc.local will execute certain command...  \n",
       "10  Persistence Persistence is achieved by the mal...  \n",
       "15   (there are several string operations, such as...  \n",
       "11  The way the malware gets information regarding...  \n",
       "5   The main method then branches to function name...  \n",
       "6   We then read data from the C2, but first, we z...  \n",
       "8   Nice, so now you're an ARM expert we can conti...  \n",
       "12  Which gives us the following output:  vaddr=0x...  \n",
       "13  The procedure ConnectServer (which is at 0xCA1...  \n",
       "16  We pass in the first parameter in the register...  \n",
       "17  For those not familiar with ARM, the beq instr...  \n",
       "19  Diving into ServerConnectCli..  ServerConnectC...  \n",
       "14  We pass in the first parameter in the register...  \n",
       "4   A string is formatted and the sed program is c...  \n",
       "18   (there are several string operations, such as...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation Pair data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>verb</th>\n",
       "      <th>mappedSyscall</th>\n",
       "      <th>asgSyscall</th>\n",
       "      <th>prettyReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persistence Persistence is achieved by the mal...</td>\n",
       "      <td>add</td>\n",
       "      <td>open() link() symlink()</td>\n",
       "      <td>open()</td>\n",
       "      <td>/etc/init\\.d/.*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Persistence Persistence is achieved by the mal...</td>\n",
       "      <td>add</td>\n",
       "      <td>open() link() symlink()</td>\n",
       "      <td>open()</td>\n",
       "      <td>/etc/rc\\.local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(there are several string operations, such as...</td>\n",
       "      <td>format</td>\n",
       "      <td>write() rename()</td>\n",
       "      <td>rename()</td>\n",
       "      <td>/etc/rc\\.local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The way the malware gets information regarding...</td>\n",
       "      <td>read</td>\n",
       "      <td>read() readlink()</td>\n",
       "      <td>read()</td>\n",
       "      <td>/proc/net/dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The main method then branches to function name...</td>\n",
       "      <td>read</td>\n",
       "      <td>read() readlink()</td>\n",
       "      <td>readlink()</td>\n",
       "      <td>/proc/self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We then read data from the C2, but first, we z...</td>\n",
       "      <td>have/set</td>\n",
       "      <td>mprotect() set_tid_address() arch_prctl() set_...</td>\n",
       "      <td>set_robust_list() mprotect() arch_prctl() set_...</td>\n",
       "      <td>0x[0-9a-zA-Z]{1,16} (mem)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence      verb  \\\n",
       "7   Persistence Persistence is achieved by the mal...       add   \n",
       "10  Persistence Persistence is achieved by the mal...       add   \n",
       "15   (there are several string operations, such as...    format   \n",
       "11  The way the malware gets information regarding...      read   \n",
       "5   The main method then branches to function name...      read   \n",
       "6   We then read data from the C2, but first, we z...  have/set   \n",
       "\n",
       "                                        mappedSyscall  \\\n",
       "7                             open() link() symlink()   \n",
       "10                            open() link() symlink()   \n",
       "15                                   write() rename()   \n",
       "11                                  read() readlink()   \n",
       "5                                   read() readlink()   \n",
       "6   mprotect() set_tid_address() arch_prctl() set_...   \n",
       "\n",
       "                                           asgSyscall  \\\n",
       "7                                              open()   \n",
       "10                                             open()   \n",
       "15                                           rename()   \n",
       "11                                             read()   \n",
       "5                                          readlink()   \n",
       "6   set_robust_list() mprotect() arch_prctl() set_...   \n",
       "\n",
       "                    prettyReg  \n",
       "7             /etc/init\\.d/.*  \n",
       "10             /etc/rc\\.local  \n",
       "15             /etc/rc\\.local  \n",
       "11              /proc/net/dev  \n",
       "5                  /proc/self  \n",
       "6   0x[0-9a-zA-Z]{1,16} (mem)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target document: Gafgyt-sectrio.csv (docs_id = 2)\n",
    "d = {\n",
    "    \"Dofloo\": \"Dofloo-SyscallParty.csv\", # Dofloo-SyscallParty.csv Securityaffairs Dofloo-Trendmicro.csv\n",
    "    \"Xorddos\": \"Xorddos-Intezer.csv\",\n",
    "    \"Gafgyt\": \"Gafgyt-sectrio.csv\",\n",
    "    \"Luabot\": \"Luabot-malwaremustdie.csv\",\n",
    "    \"Darlloz\": \"\",\n",
    "    \"Kaiten\": \"\",\n",
    "    \"Lupper\": \"\",\n",
    "    \"Turla\": \"\",\n",
    "}\n",
    "t_docs = d[family]\n",
    "t_docs_id = xor_report_names.index(t_docs)\n",
    "\n",
    "# Gather Special Token data.\n",
    "# Columns: Matched ST (regex), Entity Type, Original Sentence\n",
    "# Present Order: Sort by Entity Type then regex string.\n",
    "df_docs = df[df['report'] == t_docs]\n",
    "df_docs.sort_values(by=['objectType', 'prettyReg'])\n",
    "print(f\"Special Token data: (id#{t_docs_id} {t_docs})\")\n",
    "display(df_docs.loc[:, ['prettyReg', 'word', 'objectType', 'sentence']])\n",
    "\n",
    "# Gather Operation Pair data.\n",
    "# Columns: Original Sentence (+action, object-word), Mapped Syscall, Matched ASG OP\n",
    "# Present Order: Sort by Sentence string\n",
    "oe = OperationEvaluator()\n",
    "def get_syscall_by_verb(verb, entityType) -> str|None:\n",
    "    try:\n",
    "        altVerb = verb.split('/')[1]\n",
    "        result = oe.translate_rule(entityType, altVerb)\n",
    "    except:\n",
    "        altVerb = None\n",
    "        result = oe.translate_rule(entityType, verb)\n",
    "    if result:\n",
    "        return \" \".join([f\"{s}()\" for s in result])\n",
    "    return None\n",
    "df_op = df_docs[df_docs['verb'].notnull()]    # 過濾掉沒有動詞的 OP\n",
    "df_op = df_op[df_op['asgSyscall'].notnull()]  # 過濾掉動詞沒有對應 syscall 的 OP\n",
    "df_op.sort_values(by=['sentence', 'objectType', 'prettyReg'])\n",
    "df_op['mappedSyscall'] = df_op.apply(lambda x: get_syscall_by_verb(x['verb'], x['objectType']), axis=1)\n",
    "\n",
    "print(\"Operation Pair data:\")\n",
    "# print(df_docs.loc[:, ['sentence', 'verb', 'altVerb', 'mappedSyscall', 'asgSyscall', 'prettyReg']])\n",
    "display(df_op.loc[:, ['sentence', 'verb', 'mappedSyscall', 'asgSyscall', 'prettyReg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   2. malware -> mprotect() -> Memory Address',\n",
       " '  29. sh      -> mprotect() -> Memory Address',\n",
       " '  50. sed     -> mprotect() -> Memory Address',\n",
       " '  72. sh      -> mprotect() -> Memory Address',\n",
       " '  93. sed     -> mprotect() -> Memory Address',\n",
       " ' 105. sh      -> mprotect() -> Memory Address',\n",
       " ' 126. sed     -> mprotect() -> Memory Address',\n",
       " ' 148. sh      -> mprotect() -> Memory Address',\n",
       " ' 169. sed     -> mprotect() -> Memory Address',\n",
       " ' 191. sh      -> mprotect() -> Memory Address',\n",
       " ' 212. sed     -> mprotect() -> Memory Address',\n",
       " ' 225. sh      -> mprotect() -> Memory Address',\n",
       " ' 246. sed     -> mprotect() -> Memory Address',\n",
       " ' 259. sh      -> mprotect() -> Memory Address',\n",
       " ' 280. rm      -> mprotect() -> Memory Address',\n",
       " ' 285. sh      -> mprotect() -> Memory Address',\n",
       " ' 306. rm      -> mprotect() -> Memory Address',\n",
       " ' 311. 1531    -> mprotect() -> Memory Address',\n",
       " ' 339. 1532    -> mprotect() -> Memory Address',\n",
       " ' 348. 1533    -> mprotect() -> Memory Address']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出 op 對應的的全部 asg steps\n",
    "Utility.query_origin_steplist(asg, 'mprotect', 'Memory Address') # 0x[0-9a-zA-Z]{1,16} no result\n",
    "# Utility.query_origin_steplist(asg, 'read', r'/proc/net/dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Step.4\n",
      "Step.49\n",
      "Step.92\n",
      "Step.125\n",
      "Step.168\n",
      "Step.211\n",
      "Step.245\n"
     ]
    }
   ],
   "source": [
    "step_lst = Utility.query_origin_steplist(asg, 'set_tid_address', 'Memory Address')\n",
    "step_lst = [string.split('.')[0].strip() for string in step_lst]\n",
    "step_lst = [f\"Step.{num}\" for num in step_lst]\n",
    "print(len(step_lst))\n",
    "for step in step_lst:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We then read data from the C2, but first, we zero out the buffer that we are using and have a maximum size of 0x1380 that we want to receive.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_op.loc[14, 'sentence']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列印其他小數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mprotect',\n",
       " 'set_tid_address',\n",
       " 'arch_prctl',\n",
       " 'set_thread_area',\n",
       " 'set_robust_list']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.translate_rule('mem', 'set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" It terminates the following processes if found running in the affected system's memory:  inetd xinetd telnetd utelnetd scfgmgr Other Details  This Worm does the following:  It terminates and deletes the following processes and files: /var/run/.lightpid /var/run/.aidrapid /var/run/lightpid /var/run/.lihtpid /var/run/.lamorte/lamorte.pid /var/run/.daemon.pid \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs.loc[22].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Darlloz-Trendmicro2.csv. Matched OP count: 2\n",
      "--\n",
      "OP #2 create /var/run/.* /var/run/.zollard\n",
      "\n",
      "This Worm creates the following folders:\n",
      "\n",
      "/var/run/.zollard\n",
      "\n",
      "\n",
      "--\n",
      "OP #1 create /run/.* /var/run/.zollard\n",
      "\n",
      "This Worm creates the following folders:\n",
      "\n",
      "/var/run/.zollard\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 印出特定 report 的 matched 句子\n",
    "report_id = 5\n",
    "reportname = fset.rem_lst[report_id].reportname\n",
    "print(f\"Report: {reportname}. Matched OP count: {len(fset.rem_lst[report_id].match_doc_OPset)}\")\n",
    "for i, op in enumerate(fset.rem_lst[report_id].match_doc_OPset):\n",
    "    print(f\"--\\nOP #{op.step_number} {op.action} {op.object} {op.original_object}\")\n",
    "    print(f\"{op.original_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<OP 8 act=contain, obj=sh>, <OP 2 act=expose, obj=sed>, <OP 4 act=allow, obj=sed>, <OP11 act=None, obj=sed>, <OP 3 act=assemble, obj=sed>, <OP12 act=use, obj=sh>, <OP 1 act=scan, obj=sed>, <OP10 act=disclose, obj=sed>, <OP 5 act=gain, obj=sh>, <OP 6 act=depend, obj=sed>, <OP 7 act=execute, obj=sh>, <OP 9 act=contain, obj=sed>}\n",
      "{<OP 4 act=use, obj=sed>, <OP 7 act=None, obj=sed>, <OP 1 act=be, obj=PID.*>, <OP11 act=add, obj=sh>, <OP 6 act=None, obj=sh>, <OP 9 act=None, obj=ip_addr>, <OP 2 act=decide, obj=sh>, <OP 5 act=have, obj=sh>, <OP12 act=explain, obj=sh>, <OP10 act=be, obj=sed>, <OP 3 act=be, obj=sh>, <OP 8 act=be, obj=ip_addr>}\n",
      "{<OP 4 act=connect, obj=ip_addr>, <OP 5 act=receive, obj=sh>, <OP 2 act=download, obj=sh>, <OP 1 act=read, obj=sh>, <OP 8 act=None, obj=sed>, <OP 3 act=None, obj=sh>, <OP 7 act=None, obj=/etc/rc.*\\.d/.*>, <OP 6 act=modify, obj=/etc/rc\\.local>, <OP 9 act=be, obj=sh>}\n",
      "{<OP 8 act=use, obj=sed>, <OP 2 act=None, obj=sed>, <OP21 act=None, obj=ip_addr>, <OP13 act=format, obj=sed>, <OP 4 act=hold, obj=sed>, <OP15 act=see, obj=sed>, <OP23 act=’, obj=sed>, <OP 3 act=None, obj=sh>, <OP 6 act=None, obj=/proc/self>, <OP10 act=add, obj=/etc/init\\.d/.*>, <OP 1 act=force, obj=sh>, <OP18 act=see, obj=sh>, <OP20 act=look, obj=sh>, <OP 9 act=add, obj=/etc/rc\\.local>, <OP12 act=construct, obj=sh>, <OP 7 act=pass, obj=sed>, <OP14 act=format, obj=/etc/rc\\.local>, <OP 5 act=be, obj=sed>, <OP11 act=execute, obj=/etc/rc\\.local>, <OP24 act=indicate, obj=sed>, <OP17 act=read, obj=/proc/net/dev>, <OP22 act=pass, obj=sh>, <OP19 act=be, obj=sh>, <OP16 act=note, obj=sed>}\n",
      "{<OP 6 act=gather, obj=/proc/stat>, <OP 1 act=se, obj=sed>, <OP 9 act=None, obj=UID.*>, <OP 5 act=stop, obj=sh>, <OP 7 act=None, obj=/proc/net/dev>, <OP 2 act=se, obj=/etc/rc\\.local>, <OP 3 act=se, obj=/etc/rc.*\\.d/.*>, <OP 4 act=start, obj=/etc/init\\.d/.*>, <OP 8 act=None, obj=/proc/self>}\n"
     ]
    }
   ],
   "source": [
    "# 測試區\n",
    "for rem in fset.rem_lst:\n",
    "    print(rem.doc_OPset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin/sed</th>\n",
       "      <th>/etc/rc</th>\n",
       "      <th>/etc/init.d/</th>\n",
       "      <th>/proc/</th>\n",
       "      <th>/etc/sed</th>\n",
       "      <th>/selinux</th>\n",
       "      <th>/sys/</th>\n",
       "      <th>bin/</th>\n",
       "      <th>lsb-release</th>\n",
       "      <th>uname(.)($)</th>\n",
       "      <th>...</th>\n",
       "      <th>^sh$</th>\n",
       "      <th>^sed$</th>\n",
       "      <th>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+</th>\n",
       "      <th>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}</th>\n",
       "      <th>eth[0-9]$</th>\n",
       "      <th>0x[0-9a-zA-Z]{8}</th>\n",
       "      <th>permission:{0,1}[0-9]{0,4}</th>\n",
       "      <th>UID</th>\n",
       "      <th>GID</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin/sed  /etc/rc  /etc/init.d/  /proc/  /etc/sed  /selinux  /sys/  bin/  \\\n",
       "0         0        0             0       0         0         0      0     0   \n",
       "1         0        0             0       0         0         0      0     0   \n",
       "2         0        0             0       0         0         0      0     0   \n",
       "3         0        0             0       0         0         0      0     0   \n",
       "4         0        0             0       0         0         0      0     0   \n",
       "5         0        0             0       0         0         0      0     0   \n",
       "6         0        0             0       0         0         0      0     0   \n",
       "7         0        0             0       0         0         0      0     0   \n",
       "8         0        0             0       0         0         0      0     0   \n",
       "9         0        0             0       0         0         0      0     0   \n",
       "10        0        0             0       0         0         0      0     0   \n",
       "11        0        0             0       0         0         0      0     0   \n",
       "12        0        0             0       0         0         0      0     0   \n",
       "13        0        0             0       0         0         0      0     0   \n",
       "14        0        0             0       0         0         0      0     0   \n",
       "\n",
       "    lsb-release  uname(.)($)  ...  ^sh$  ^sed$  \\\n",
       "0             0            0  ...     0      0   \n",
       "1             0            0  ...     0      0   \n",
       "2             0            0  ...     0      0   \n",
       "3             0            0  ...     0      0   \n",
       "4             0            0  ...     0      0   \n",
       "5             0            0  ...     0      0   \n",
       "6             0            0  ...     0      0   \n",
       "7             0            0  ...     0      0   \n",
       "8             0            0  ...     0      0   \n",
       "9             0            0  ...     0      0   \n",
       "10            0            0  ...     0      0   \n",
       "11            0            0  ...     0      0   \n",
       "12            0            0  ...     0      0   \n",
       "13            0            0  ...     0      0   \n",
       "14            0            0  ...     0      0   \n",
       "\n",
       "    \\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "11                                       0   \n",
       "12                                       0   \n",
       "13                                       0   \n",
       "14                                       0   \n",
       "\n",
       "    \\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}  eth[0-9]$  0x[0-9a-zA-Z]{8}  \\\n",
       "0                                    0          0                 0   \n",
       "1                                    0          0                 0   \n",
       "2                                    0          0                 0   \n",
       "3                                    0          0                 0   \n",
       "4                                    0          0                 0   \n",
       "5                                    0          0                 0   \n",
       "6                                    0          0                 0   \n",
       "7                                    0          0                 0   \n",
       "8                                    0          0                 0   \n",
       "9                                    0          0                 0   \n",
       "10                                   0          0                 0   \n",
       "11                                   0          0                 0   \n",
       "12                                   0          0                 0   \n",
       "13                                   0          0                 0   \n",
       "14                                   0          0                 0   \n",
       "\n",
       "    permission:{0,1}[0-9]{0,4}  UID  GID  match  \n",
       "0                            0    0    0      0  \n",
       "1                            0    0    0      0  \n",
       "2                            0    0    0      0  \n",
       "3                            0    0    0      0  \n",
       "4                            0    0    0      0  \n",
       "5                            0    0    0      0  \n",
       "6                            0    0    0      0  \n",
       "7                            0    0    0      0  \n",
       "8                            0    0    0      0  \n",
       "9                            0    0    0      0  \n",
       "10                           0    0    0      0  \n",
       "11                           0    0    0      0  \n",
       "12                           0    0    0      0  \n",
       "13                           0    0    0      0  \n",
       "14                           0    0    0      0  \n",
       "\n",
       "[15 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for rem in fset.rem_lst:\n",
    "    display(rem.get_match_sentences())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "125a1d8b627fe68767755740015967bae857d08bb92fb3fd0d9d8ed24f978d39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
